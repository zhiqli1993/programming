# Go语言并发实战案例

## 📚 学习目标
通过实际案例掌握Go语言并发编程在真实项目中的应用，理解如何设计和实现高效可靠的并发系统。

---

## 1. 并发网络爬虫

### 1.1 基本架构
```go
package main

import (
    "fmt"
    "io"
    "log"
    "net/http"
    "net/url"
    "os"
    "path/filepath"
    "strings"
    "sync"
    "time"

    "golang.org/x/net/html"
)

// 爬虫配置
type Crawler struct {
    baseURL      string
    depth        int
    maxGoroutine int
    visited      map[string]bool
    mutex        sync.Mutex
    wg           sync.WaitGroup
    semaphore    chan struct{}
}

// 创建新爬虫
func NewCrawler(baseURL string, depth, maxGoroutine int) *Crawler {
    return &Crawler{
        baseURL:      baseURL,
        depth:        depth,
        maxGoroutine: maxGoroutine,
        visited:      make(map[string]bool),
        semaphore:    make(chan struct{}, maxGoroutine),
    }
}

// 开始爬取
func (c *Crawler) Start() {
    fmt.Printf("开始爬取 %s，最大深度 %d，并发数 %d\n", c.baseURL, c.depth, c.maxGoroutine)
    startTime := time.Now()
    
    c.crawl(c.baseURL, 1)
    c.wg.Wait()
    
    elapsed := time.Since(startTime)
    fmt.Printf("爬取完成，耗时 %v，访问了 %d 个URL\n", elapsed, len(c.visited))
}

// 爬取页面
func (c *Crawler) crawl(urlStr string, depth int) {
    if depth > c.depth {
        return
    }
    
    // 检查URL是否已经访问过
    c.mutex.Lock()
    if c.visited[urlStr] {
        c.mutex.Unlock()
        return
    }
    c.visited[urlStr] = true
    c.mutex.Unlock()
    
    // 增加等待组计数
    c.wg.Add(1)
    
    // 并发爬取
    go func() {
        defer c.wg.Done()
        
        // 获取信号量
        c.semaphore <- struct{}{}
        defer func() { <-c.semaphore }()
        
        // 获取页面内容
        fmt.Printf("爬取: %s (深度: %d)\n", urlStr, depth)
        links, err := c.fetchLinks(urlStr)
        if err != nil {
            log.Printf("爬取 %s 时出错: %v\n", urlStr, err)
            return
        }
        
        // 递归爬取链接
        for _, link := range links {
            c.crawl(link, depth+1)
        }
    }()
}

// 获取页面中的链接
func (c *Crawler) fetchLinks(urlStr string) ([]string, error) {
    resp, err := http.Get(urlStr)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("状态码: %d", resp.StatusCode)
    }
    
    // 解析HTML
    doc, err := html.Parse(resp.Body)
    if err != nil {
        return nil, err
    }
    
    var links []string
    baseURL, err := url.Parse(urlStr)
    if err != nil {
        return nil, err
    }
    
    // 提取链接
    visitNode := func(n *html.Node) {
        if n.Type == html.ElementNode && n.Data == "a" {
            for _, a := range n.Attr {
                if a.Key == "href" {
                    link, err := resolveURL(baseURL, a.Val)
                    if err != nil {
                        continue
                    }
                    
                    // 只处理同一域名下的链接
                    if baseURL.Hostname() == link.Hostname() {
                        links = append(links, link.String())
                    }
                    break
                }
            }
        }
    }
    
    // 遍历HTML节点
    var traverse func(*html.Node)
    traverse = func(n *html.Node) {
        visitNode(n)
        for c := n.FirstChild; c != nil; c = c.NextSibling {
            traverse(c)
        }
    }
    traverse(doc)
    
    return links, nil
}

// 解析URL
func resolveURL(base *url.URL, href string) (*url.URL, error) {
    link, err := url.Parse(href)
    if err != nil {
        return nil, err
    }
    return base.ResolveReference(link), nil
}

func main() {
    // 创建并启动爬虫
    crawler := NewCrawler("https://golang.org", 2, 10)
    crawler.Start()
}
```

### 1.2 添加结果存储
```go
// 添加到上述代码中

// 页面内容存储
type PageStore struct {
    baseDir string
    mutex   sync.Mutex
}

// 创建存储
func NewPageStore(baseDir string) *PageStore {
    // 确保目录存在
    os.MkdirAll(baseDir, 0755)
    return &PageStore{
        baseDir: baseDir,
    }
}

// 存储页面内容
func (ps *PageStore) SavePage(pageURL string, content []byte) error {
    ps.mutex.Lock()
    defer ps.mutex.Unlock()
    
    // 生成文件名
    parsedURL, err := url.Parse(pageURL)
    if err != nil {
        return err
    }
    
    // 创建路径
    path := parsedURL.Path
    if path == "" || path == "/" {
        path = "/index.html"
    } else if !strings.HasSuffix(path, ".html") {
        path = path + ".html"
    }
    
    // 确保父目录存在
    fullPath := filepath.Join(ps.baseDir, parsedURL.Hostname(), path)
    dir := filepath.Dir(fullPath)
    if err := os.MkdirAll(dir, 0755); err != nil {
        return err
    }
    
    // 写入文件
    return os.WriteFile(fullPath, content, 0644)
}

// 修改爬虫结构
type Crawler struct {
    // ... 原有字段 ...
    store       *PageStore
}

// 修改构造函数
func NewCrawler(baseURL string, depth, maxGoroutine int) *Crawler {
    return &Crawler{
        baseURL:      baseURL,
        depth:        depth,
        maxGoroutine: maxGoroutine,
        visited:      make(map[string]bool),
        semaphore:    make(chan struct{}, maxGoroutine),
        store:        NewPageStore("./crawled_pages"),
    }
}

// 修改fetchLinks函数以保存内容
func (c *Crawler) fetchLinks(urlStr string) ([]string, error) {
    resp, err := http.Get(urlStr)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("状态码: %d", resp.StatusCode)
    }
    
    // 读取内容
    content, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, err
    }
    
    // 保存页面
    if err := c.store.SavePage(urlStr, content); err != nil {
        log.Printf("保存页面 %s 失败: %v\n", urlStr, err)
    }
    
    // 重置响应体
    resp.Body = io.NopCloser(strings.NewReader(string(content)))
    
    // ... 原有的HTML解析代码 ...
}
```

---

## 2. 并发数据处理管道

### 2.1 CSV数据处理管道
```go
package main

import (
    "encoding/csv"
    "fmt"
    "io"
    "log"
    "os"
    "strconv"
    "sync"
    "time"
)

// 数据结构
type Record struct {
    ID     int
    Name   string
    Value  float64
    Status string
}

// 阶段1: 读取CSV记录
func recordGenerator(filename string) (<-chan Record, <-chan error, func()) {
    records := make(chan Record)
    errc := make(chan error, 1)
    done := make(chan struct{})
    
    go func() {
        defer close(records)
        defer close(errc)
        
        file, err := os.Open(filename)
        if err != nil {
            errc <- err
            return
        }
        defer file.Close()
        
        reader := csv.NewReader(file)
        // 跳过标题行
        _, err = reader.Read()
        if err != nil {
            errc <- err
            return
        }
        
        for {
            select {
            case <-done:
                return
            default:
                row, err := reader.Read()
                if err == io.EOF {
                    return
                }
                if err != nil {
                    errc <- err
                    return
                }
                
                // 解析数据
                id, err := strconv.Atoi(row[0])
                if err != nil {
                    log.Printf("解析ID错误: %v", err)
                    continue
                }
                
                value, err := strconv.ParseFloat(row[2], 64)
                if err != nil {
                    log.Printf("解析Value错误: %v", err)
                    continue
                }
                
                // 创建记录
                record := Record{
                    ID:     id,
                    Name:   row[1],
                    Value:  value,
                    Status: row[3],
                }
                
                records <- record
            }
        }
    }()
    
    // 返回取消函数
    cancel := func() {
        close(done)
    }
    
    return records, errc, cancel
}

// 阶段2: 数据转换
func dataTransformer(in <-chan Record) <-chan Record {
    out := make(chan Record)
    
    go func() {
        defer close(out)
        for record := range in {
            // 转换值
            record.Value = record.Value * 1.1 // 增加10%
            
            // 修改状态
            if record.Value > 1000 {
                record.Status = "High"
            } else if record.Value > 500 {
                record.Status = "Medium"
            } else {
                record.Status = "Low"
            }
            
            out <- record
        }
    }()
    
    return out
}

// 阶段3: 过滤记录
func recordFilter(in <-chan Record, condition func(Record) bool) <-chan Record {
    out := make(chan Record)
    
    go func() {
        defer close(out)
        for record := range in {
            if condition(record) {
                out <- record
            }
        }
    }()
    
    return out
}

// 阶段4: 记录汇总
func recordAggregator(in <-chan Record) <-chan map[string]float64 {
    out := make(chan map[string]float64)
    
    go func() {
        defer close(out)
        
        totals := make(map[string]float64)
        
        for record := range in {
            totals[record.Status] += record.Value
        }
        
        out <- totals
    }()
    
    return out
}

// 阶段5: 并行数据处理
func parallelProcessor(in <-chan Record, numWorkers int, processorFunc func(Record) Record) <-chan Record {
    out := make(chan Record)
    
    var wg sync.WaitGroup
    wg.Add(numWorkers)
    
    // 启动多个工作者
    for i := 0; i < numWorkers; i++ {
        go func() {
            defer wg.Done()
            for record := range in {
                processed := processorFunc(record)
                out <- processed
            }
        }()
    }
    
    // 当所有工作者完成后关闭输出通道
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

func main() {
    // 创建测试CSV文件
    createTestCSV("test_data.csv", 10000)
    
    start := time.Now()
    
    // 阶段1: 读取记录
    records, errc, cancel := recordGenerator("test_data.csv")
    defer cancel()
    
    // 阶段2: 并行处理记录
    processor := func(r Record) Record {
        // 模拟复杂处理
        time.Sleep(time.Millisecond)
        r.Value = r.Value * 1.1
        return r
    }
    processedRecords := parallelProcessor(records, 4, processor)
    
    // 阶段3: 过滤记录
    filter := func(r Record) bool {
        return r.Value > 200
    }
    filteredRecords := recordFilter(processedRecords, filter)
    
    // 阶段4: 汇总结果
    resultChan := recordAggregator(filteredRecords)
    
    // 处理错误
    go func() {
        for err := range errc {
            log.Printf("处理错误: %v", err)
        }
    }()
    
    // 获取结果
    result := <-resultChan
    
    // 输出结果
    fmt.Println("处理结果:")
    for status, total := range result {
        fmt.Printf("状态 %s: 总值 %.2f\n", status, total)
    }
    
    fmt.Printf("处理时间: %v\n", time.Since(start))
}

// 创建测试数据
func createTestCSV(filename string, numRecords int) {
    file, err := os.Create(filename)
    if err != nil {
        log.Fatalf("创建测试文件失败: %v", err)
    }
    defer file.Close()
    
    writer := csv.NewWriter(file)
    defer writer.Flush()
    
    // 写入标题
    writer.Write([]string{"ID", "Name", "Value", "Status"})
    
    // 写入数据
    for i := 1; i <= numRecords; i++ {
        value := strconv.FormatFloat(float64(i%1000), 'f', 2, 64)
        status := "Active"
        if i%5 == 0 {
            status = "Inactive"
        }
        
        writer.Write([]string{
            strconv.Itoa(i),
            fmt.Sprintf("Item %d", i),
            value,
            status,
        })
    }
}
```

---

## 3. 并发API服务器

### 3.1 基本结构
```go
package main

import (
    "context"
    "encoding/json"
    "log"
    "net/http"
    "os"
    "os/signal"
    "sync"
    "syscall"
    "time"
)

// 数据类型
type Item struct {
    ID    int    `json:"id"`
    Name  string `json:"name"`
    Value int    `json:"value"`
}

// 数据存储
type ItemStore struct {
    items map[int]Item
    mutex sync.RWMutex
}

// 创建存储
func NewItemStore() *ItemStore {
    return &ItemStore{
        items: make(map[int]Item),
    }
}

// 获取项目
func (s *ItemStore) GetItem(id int) (Item, bool) {
    s.mutex.RLock()
    defer s.mutex.RUnlock()
    
    item, exists := s.items[id]
    return item, exists
}

// 获取所有项目
func (s *ItemStore) GetAllItems() []Item {
    s.mutex.RLock()
    defer s.mutex.RUnlock()
    
    result := make([]Item, 0, len(s.items))
    for _, item := range s.items {
        result = append(result, item)
    }
    
    return result
}

// 添加或更新项目
func (s *ItemStore) SetItem(item Item) {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    s.items[item.ID] = item
}

// 删除项目
func (s *ItemStore) DeleteItem(id int) {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    delete(s.items, id)
}

// 处理函数
type APIHandler struct {
    store *ItemStore
}

// 处理所有项目
func (h *APIHandler) handleItems(w http.ResponseWriter, r *http.Request) {
    switch r.Method {
    case http.MethodGet:
        // 获取所有项目
        items := h.store.GetAllItems()
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "items": items,
        })
        
    case http.MethodPost:
        // 添加项目
        var item Item
        if err := json.NewDecoder(r.Body).Decode(&item); err != nil {
            http.Error(w, "Invalid request body", http.StatusBadRequest)
            return
        }
        
        h.store.SetItem(item)
        
        w.Header().Set("Content-Type", "application/json")
        w.WriteHeader(http.StatusCreated)
        json.NewEncoder(w).Encode(map[string]interface{}{
            "message": "Item created",
            "item":    item,
        })
        
    default:
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
    }
}

// 处理单个项目
func (h *APIHandler) handleItem(w http.ResponseWriter, r *http.Request) {
    // 从URL提取ID
    id := 0 // 在实际应用中应该从URL路径解析
    
    switch r.Method {
    case http.MethodGet:
        // 获取项目
        item, exists := h.store.GetItem(id)
        if !exists {
            http.Error(w, "Item not found", http.StatusNotFound)
            return
        }
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(item)
        
    case http.MethodPut:
        // 更新项目
        var item Item
        if err := json.NewDecoder(r.Body).Decode(&item); err != nil {
            http.Error(w, "Invalid request body", http.StatusBadRequest)
            return
        }
        
        item.ID = id
        h.store.SetItem(item)
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "message": "Item updated",
            "item":    item,
        })
        
    case http.MethodDelete:
        // 删除项目
        h.store.DeleteItem(id)
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "message": "Item deleted",
        })
        
    default:
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
    }
}

func main() {
    // 创建数据存储
    store := NewItemStore()
    handler := &APIHandler{store: store}
    
    // 设置处理函数
    mux := http.NewServeMux()
    mux.HandleFunc("/api/items", handler.handleItems)
    mux.HandleFunc("/api/items/", handler.handleItem)
    
    // 创建服务器
    server := &http.Server{
        Addr:    ":8080",
        Handler: mux,
    }
    
    // 优雅关闭通道
    done := make(chan bool, 1)
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    
    // 启动服务器
    go func() {
        log.Println("服务器启动在 :8080")
        if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.Fatalf("启动服务器错误: %v", err)
        }
    }()
    
    // 监听关闭信号
    go func() {
        <-quit
        log.Println("服务器关闭中...")
        
        // 创建超时上下文
        ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()
        
        // 关闭服务器
        if err := server.Shutdown(ctx); err != nil {
            log.Fatalf("服务器关闭错误: %v", err)
        }
        
        close(done)
    }()
    
    <-done
    log.Println("服务器已停止")
}
```

### 3.2 添加缓存和限流
```go
// 在上述代码基础上添加

import (
    "golang.org/x/time/rate"
    "sync"
    "time"
)

// 添加缓存
type Cache struct {
    items      map[string]cacheItem
    mutex      sync.RWMutex
    expiration time.Duration
}

type cacheItem struct {
    value      []byte
    expiration time.Time
}

// 创建缓存
func NewCache(expiration time.Duration) *Cache {
    cache := &Cache{
        items:      make(map[string]cacheItem),
        expiration: expiration,
    }
    
    // 定期清理过期项
    go cache.startCleanup()
    
    return cache
}

// 设置缓存项
func (c *Cache) Set(key string, value []byte) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    c.items[key] = cacheItem{
        value:      value,
        expiration: time.Now().Add(c.expiration),
    }
}

// 获取缓存项
func (c *Cache) Get(key string) ([]byte, bool) {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    
    item, found := c.items[key]
    if !found {
        return nil, false
    }
    
    // 检查是否过期
    if time.Now().After(item.expiration) {
        return nil, false
    }
    
    return item.value, true
}

// 删除缓存项
func (c *Cache) Delete(key string) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    delete(c.items, key)
}

// 清理过期项
func (c *Cache) startCleanup() {
    ticker := time.NewTicker(time.Minute)
    defer ticker.Stop()
    
    for range ticker.C {
        c.mutex.Lock()
        
        now := time.Now()
        for key, item := range c.items {
            if now.After(item.expiration) {
                delete(c.items, key)
            }
        }
        
        c.mutex.Unlock()
    }
}

// 限流中间件
type RateLimiter struct {
    limiter *rate.Limiter
}

func NewRateLimiter(rps float64, burst int) *RateLimiter {
    return &RateLimiter{
        limiter: rate.NewLimiter(rate.Limit(rps), burst),
    }
}

func (rl *RateLimiter) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        if !rl.limiter.Allow() {
            http.Error(w, "Too many requests", http.StatusTooManyRequests)
            return
        }
        next.ServeHTTP(w, r)
    })
}

// 缓存中间件
type CacheMiddleware struct {
    cache *Cache
}

func NewCacheMiddleware(expiration time.Duration) *CacheMiddleware {
    return &CacheMiddleware{
        cache: NewCache(expiration),
    }
}

func (cm *CacheMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // 只缓存GET请求
        if r.Method != http.MethodGet {
            next.ServeHTTP(w, r)
            return
        }
        
        // 使用URL作为缓存键
        key := r.URL.String()
        
        // 查找缓存
        if cached, found := cm.cache.Get(key); found {
            w.Header().Set("Content-Type", "application/json")
            w.Header().Set("X-Cache", "HIT")
            w.Write(cached)
            return
        }
        
        // 自定义响应写入器以捕获响应
        crw := &cacheResponseWriter{
            ResponseWriter: w,
            statusCode:     http.StatusOK,
            body:           &bytes.Buffer{},
        }
        
        // 调用下一个处理器
        next.ServeHTTP(crw, r)
        
        // 只缓存成功响应
        if crw.statusCode == http.StatusOK {
            cm.cache.Set(key, crw.body.Bytes())
        }
    })
}

// 缓存响应写入器
type cacheResponseWriter struct {
    http.ResponseWriter
    statusCode int
    body       *bytes.Buffer
}

func (crw *cacheResponseWriter) WriteHeader(statusCode int) {
    crw.statusCode = statusCode
    crw.ResponseWriter.WriteHeader(statusCode)
}

func (crw *cacheResponseWriter) Write(b []byte) (int, error) {
    crw.body.Write(b)
    return crw.ResponseWriter.Write(b)
}

// 在main函数中应用中间件
func main() {
    // ... 原有代码 ...
    
    // 创建中间件
    rateLimiter := NewRateLimiter(100, 50) // 限制每秒100个请求，突发50个
    cacheMiddleware := NewCacheMiddleware(5 * time.Minute) // 缓存5分钟
    
    // 设置处理函数
    mux := http.NewServeMux()
    mux.HandleFunc("/api/items", handler.handleItems)
    mux.HandleFunc("/api/items/", handler.handleItem)
    
    // 应用中间件
    var handler http.Handler = mux
    handler = rateLimiter.Middleware(handler)
    handler = cacheMiddleware.Middleware(handler)
    
    // 创建服务器
    server := &http.Server{
        Addr:    ":8080",
        Handler: handler,
    }
    
    // ... 原有代码 ...
}
```

---

## 4. 实时数据处理系统

### 4.1 使用Channel构建数据流水线
```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "math/rand"
    "os"
    "os/signal"
    "sync"
    "syscall"
    "time"
)

// 数据结构
type SensorData struct {
    ID        string    `json:"id"`
    Type      string    `json:"type"`
    Value     float64   `json:"value"`
    Timestamp time.Time `json:"timestamp"`
}

// 结果结构
type ProcessedData struct {
    SensorID    string  `json:"sensor_id"`
    SensorType  string  `json:"sensor_type"`
    AverageValue float64 `json:"average_value"`
    MinValue    float64 `json:"min_value"`
    MaxValue    float64 `json:"max_value"`
    Count       int     `json:"count"`
    Window      string  `json:"window"`
}

// 数据生成器
func generateData(ctx context.Context, rate int) <-chan SensorData {
    out := make(chan SensorData)
    
    go func() {
        defer close(out)
        
        ticker := time.NewTicker(time.Second / time.Duration(rate))
        defer ticker.Stop()
        
        sensorTypes := []string{"temperature", "humidity", "pressure", "light"}
        sensorCount := 10
        
        for {
            select {
            case <-ctx.Done():
                return
            case <-ticker.C:
                // 生成随机传感器数据
                sensorID := fmt.Sprintf("sensor-%d", rand.Intn(sensorCount))
                sensorType := sensorTypes[rand.Intn(len(sensorTypes))]
                
                // 根据传感器类型生成合理的值
                var value float64
                switch sensorType {
                case "temperature":
                    value = 20 + rand.Float64()*10 // 20-30°C
                case "humidity":
                    value = 30 + rand.Float64()*50 // 30-80%
                case "pressure":
                    value = 980 + rand.Float64()*40 // 980-1020 hPa
                case "light":
                    value = rand.Float64() * 1000 // 0-1000 lux
                }
                
                data := SensorData{
                    ID:        sensorID,
                    Type:      sensorType,
                    Value:     value,
                    Timestamp: time.Now(),
                }
                
                out <- data
            }
        }
    }()
    
    return out
}

// 数据过滤器
func filterData(ctx context.Context, in <-chan SensorData, filterFn func(SensorData) bool) <-chan SensorData {
    out := make(chan SensorData)
    
    go func() {
        defer close(out)
        
        for {
            select {
            case <-ctx.Done():
                return
            case data, ok := <-in:
                if !ok {
                    return
                }
                
                if filterFn(data) {
                    out <- data
                }
            }
        }
    }()
    
    return out
}

// 数据窗口聚合
func windowedAggregation(ctx context.Context, in <-chan SensorData, windowSize time.Duration) <-chan ProcessedData {
    out := make(chan ProcessedData)
    
    go func() {
        defer close(out)
        
        // 保存每个传感器的数据
        type sensorStats struct {
            values   []float64
            count    int
            sum      float64
            min      float64
            max      float64
            lastSent time.Time
        }
        
        stats := make(map[string]*sensorStats)
        ticker := time.NewTicker(windowSize)
        defer ticker.Stop()
        
        for {
            select {
            case <-ctx.Done():
                return
            case data, ok := <-in:
                if !ok {
                    return
                }
                
                // 为传感器创建统计信息
                key := data.ID + "-" + data.Type
                if _, exists := stats[key]; !exists {
                    stats[key] = &sensorStats{
                        values:   make([]float64, 0),
                        min:      data.Value,
                        max:      data.Value,
                        lastSent: time.Now(),
                    }
                }
                
                s := stats[key]
                s.values = append(s.values, data.Value)
                s.count++
                s.sum += data.Value
                
                // 更新最小值和最大值
                if data.Value < s.min {
                    s.min = data.Value
                }
                if data.Value > s.max {
                    s.max = data.Value
                }
                
            case <-ticker.C:
                // 发送所有传感器的聚合数据
                now := time.Now()
                windowStr := fmt.Sprintf("%s - %s", now.Add(-windowSize).Format(time.RFC3339), now.Format(time.RFC3339))
                
                for key, s := range stats {
                    if s.count == 0 {
                        continue
                    }
                    
                    // 解析ID和类型
                    parts := strings.Split(key, "-")
                    sensorID := parts[0]
                    sensorType := parts[1]
                    
                    // 创建处理后的数据
                    processed := ProcessedData{
                        SensorID:     sensorID,
                        SensorType:   sensorType,
                        AverageValue: s.sum / float64(s.count),
                        MinValue:     s.min,
                        MaxValue:     s.max,
                        Count:        s.count,
                        Window:       windowStr,
                    }
                    
                    // 发送结果
                    out <- processed
                    
                    // 重置统计信息
                    stats[key] = &sensorStats{
                        values:   make([]float64, 0),
                        min:      math.MaxFloat64,
                        max:      -math.MaxFloat64,
                        lastSent: now,
                    }
                }
            }
        }
    }()
    
    return out
}

// 数据持久化
func persistData(ctx context.Context, in <-chan ProcessedData) {
    // 打开或创建输出文件
    file, err := os.OpenFile("sensor_data.json", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    if err != nil {
        log.Fatalf("创建输出文件失败: %v", err)
    }
    defer file.Close()
    
    encoder := json.NewEncoder(file)
    
    for {
        select {
        case <-ctx.Done():
            return
        case data, ok := <-in:
            if !ok {
                return
            }
            
            // 写入文件
            if err := encoder.Encode(data); err != nil {
                log.Printf("写入数据失败: %v", err)
            }
            
            // 也输出到控制台
            fmt.Printf("处理数据: %s (%s) - 平均值: %.2f, 最小值: %.2f, 最大值: %.2f, 数量: %d\n",
                data.SensorID, data.SensorType, data.AverageValue, data.MinValue, data.MaxValue, data.Count)
        }
    }
}

func main() {
    // 设置随机数种子
    rand.Seed(time.Now().UnixNano())
    
    // 创建取消上下文
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    // 构建数据流水线
    rawData := generateData(ctx, 50) // 每秒生成50个数据点
    
    // 过滤无效数据
    validData := filterData(ctx, rawData, func(data SensorData) bool {
        // 简单的有效性检查
        switch data.Type {
        case "temperature":
            return data.Value >= -30 && data.Value <= 50
        case "humidity":
            return data.Value >= 0 && data.Value <= 100
        case "pressure":
            return data.Value >= 900 && data.Value <= 1100
        case "light":
            return data.Value >= 0 && data.Value <= 2000
        default:
            return false
        }
    })
    
    // 聚合数据
    aggregatedData := windowedAggregation(ctx, validData, 5*time.Second) // 5秒窗口
    
    // 启动持久化协程
    go persistData(ctx, aggregatedData)
    
    // 等待中断信号
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
    
    fmt.Println("实时数据处理系统启动。按Ctrl+C停止...")
    <-sigChan
    
    fmt.Println("\n正在停止...")
    cancel()
    time.Sleep(time.Second) // 给goroutines时间清理
    fmt.Println("已停止")
}
```

---

## 5. 分布式任务系统

### 5.1 Worker任务处理框架
```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "math/rand"
    "sync"
    "time"
)

// 任务定义
type Task struct {
    ID        string          `json:"id"`
    Type      string          `json:"type"`
    Data      json.RawMessage `json:"data"`
    CreatedAt time.Time       `json:"created_at"`
    Status    string          `json:"status"`
    Result    interface{}     `json:"result,omitempty"`
    Error     string          `json:"error,omitempty"`
}

// 任务处理接口
type TaskProcessor interface {
    ProcessTask(ctx context.Context, task Task) (interface{}, error)
}

// 任务处理器映射
var processors = make(map[string]TaskProcessor)

// 注册任务处理器
func RegisterProcessor(taskType string, processor TaskProcessor) {
    processors[taskType] = processor
}

// 任务队列
type TaskQueue struct {
    tasks  chan Task
    closed bool
    mutex  sync.RWMutex
}

// 创建任务队列
func NewTaskQueue(capacity int) *TaskQueue {
    return &TaskQueue{
        tasks: make(chan Task, capacity),
    }
}

// 添加任务
func (q *TaskQueue) AddTask(task Task) error {
    q.mutex.RLock()
    defer q.mutex.RUnlock()
    
    if q.closed {
        return fmt.Errorf("task queue is closed")
    }
    
    q.tasks <- task
    return nil
}

// 关闭队列
func (q *TaskQueue) Close() {
    q.mutex.Lock()
    defer q.mutex.Unlock()
    
    if !q.closed {
        q.closed = true
        close(q.tasks)
    }
}

// 任务结果存储
type TaskResultStore interface {
    SaveResult(task Task) error
    GetTaskByID(id string) (Task, error)
}

// 内存任务结果存储
type MemoryTaskStore struct {
    tasks map[string]Task
    mutex sync.RWMutex
}

// 创建内存任务存储
func NewMemoryTaskStore() *MemoryTaskStore {
    return &MemoryTaskStore{
        tasks: make(map[string]Task),
    }
}

// 保存任务结果
func (s *MemoryTaskStore) SaveResult(task Task) error {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    s.tasks[task.ID] = task
    return nil
}

// 获取任务
func (s *MemoryTaskStore) GetTaskByID(id string) (Task, error) {
    s.mutex.RLock()
    defer s.mutex.RUnlock()
    
    task, exists := s.tasks[id]
    if !exists {
        return Task{}, fmt.Errorf("task with ID %s not found", id)
    }
    
    return task, nil
}

// 工作者
type Worker struct {
    id       int
    queue    *TaskQueue
    store    TaskResultStore
    stopChan chan struct{}
    wg       *sync.WaitGroup
}

// 创建工作者
func NewWorker(id int, queue *TaskQueue, store TaskResultStore, wg *sync.WaitGroup) *Worker {
    return &Worker{
        id:       id,
        queue:    queue,
        store:    store,
        stopChan: make(chan struct{}),
        wg:       wg,
    }
}

// 启动工作者
func (w *Worker) Start() {
    w.wg.Add(1)
    go w.run()
}

// 停止工作者
func (w *Worker) Stop() {
    close(w.stopChan)
}

// 工作者主循环
func (w *Worker) run() {
    defer w.wg.Done()
    
    log.Printf("Worker %d started", w.id)
    
    for {
        select {
        case <-w.stopChan:
            log.Printf("Worker %d stopping", w.id)
            return
        case task, ok := <-w.queue.tasks:
            if !ok {
                log.Printf("Worker %d: queue closed", w.id)
                return
            }
            
            w.processTask(task)
        }
    }
}

// 处理任务
func (w *Worker) processTask(task Task) {
    log.Printf("Worker %d processing task %s of type %s", w.id, task.ID, task.Type)
    
    // 更新任务状态
    task.Status = "processing"
    w.store.SaveResult(task)
    
    // 创建上下文
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    // 获取处理器
    processor, exists := processors[task.Type]
    if !exists {
        task.Status = "failed"
        task.Error = fmt.Sprintf("no processor found for task type %s", task.Type)
        w.store.SaveResult(task)
        log.Printf("Worker %d: %s", w.id, task.Error)
        return
    }
    
    // 处理任务
    result, err := processor.ProcessTask(ctx, task)
    
    // 更新任务状态
    if err != nil {
        task.Status = "failed"
        task.Error = err.Error()
    } else {
        task.Status = "completed"
        task.Result = result
    }
    
    // 保存结果
    w.store.SaveResult(task)
    
    log.Printf("Worker %d completed task %s with status %s", w.id, task.ID, task.Status)
}

// 简单数学任务处理器
type MathTaskProcessor struct{}

func (p *MathTaskProcessor) ProcessTask(ctx context.Context, task Task) (interface{}, error) {
    // 解析任务数据
    var data struct {
        Operation string  `json:"operation"`
        A         float64 `json:"a"`
        B         float64 `json:"b"`
    }
    
    if err := json.Unmarshal(task.Data, &data); err != nil {
        return nil, fmt.Errorf("invalid task data: %v", err)
    }
    
    // 模拟处理时间
    processingTime := time.Duration(rand.Intn(3000)) * time.Millisecond
    
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    case <-time.After(processingTime):
        // 处理不同操作
        switch data.Operation {
        case "add":
            return data.A + data.B, nil
        case "subtract":
            return data.A - data.B, nil
        case "multiply":
            return data.A * data.B, nil
        case "divide":
            if data.B == 0 {
                return nil, fmt.Errorf("division by zero")
            }
            return data.A / data.B, nil
        default:
            return nil, fmt.Errorf("unknown operation: %s", data.Operation)
        }
    }
}

// 主函数
func main() {
    // 设置随机数种子
    rand.Seed(time.Now().UnixNano())
    
    // 注册任务处理器
    RegisterProcessor("math", &MathTaskProcessor{})
    
    // 创建任务队列和结果存储
    queue := NewTaskQueue(100)
    store := NewMemoryTaskStore()
    
    // 创建工作者池
    var wg sync.WaitGroup
    numWorkers := 5
    workers := make([]*Worker, numWorkers)
    
    for i := 0; i < numWorkers; i++ {
        workers[i] = NewWorker(i+1, queue, store, &wg)
        workers[i].Start()
    }
    
    // 创建一些任务
    operations := []string{"add", "subtract", "multiply", "divide"}
    
    for i := 0; i < 20; i++ {
        operation := operations[rand.Intn(len(operations))]
        
        taskData := struct {
            Operation string  `json:"operation"`
            A         float64 `json:"a"`
            B         float64 `json:"b"`
        }{
            Operation: operation,
            A:         float64(rand.Intn(100)),
            B:         float64(rand.Intn(10)),
        }
        
        data, _ := json.Marshal(taskData)
        
        task := Task{
            ID:        fmt.Sprintf("task-%d", i+1),
            Type:      "math",
            Data:      json.RawMessage(data),
            CreatedAt: time.Now(),
            Status:    "pending",
        }
        
        if err := queue.AddTask(task); err != nil {
            log.Printf("Failed to add task: %v", err)
            continue
        }
        
        log.Printf("Added task %s: %s %v %v", task.ID, taskData.Operation, taskData.A, taskData.B)
    }
    
    // 等待所有任务完成
    time.Sleep(2 * time.Second)
    log.Println("Stopping workers...")
    
    // 停止工作者
    for _, worker := range workers {
        worker.Stop()
    }
    
    // 关闭队列
    queue.Close()
    
    // 等待所有工作者完成
    wg.Wait()
    
    // 输出任务结果
    log.Println("\nTask results:")
    for i := 0; i < 20; i++ {
        taskID := fmt.Sprintf("task-%d", i+1)
        task, err := store.GetTaskByID(taskID)
        if err != nil {
            log.Printf("Failed to get task %s: %v", taskID, err)
            continue
        }
        
        var taskData struct {
            Operation string  `json:"operation"`
            A         float64 `json:"a"`
            B         float64 `json:"b"`
        }
        json.Unmarshal(task.Data, &taskData)
        
        if task.Status == "completed" {
            log.Printf("Task %s: %v %s %v = %v", task.ID, taskData.A, taskData.Operation, taskData.B, task.Result)
        } else {
            log.Printf("Task %s: %v %s %v - %s: %s", task.ID, taskData.A, taskData.Operation, taskData.B, task.Status, task.Error)
        }
    }
}
```

---

## 6. 学习检查点

- [ ] 理解并发网络爬虫的设计原理和实现
- [ ] 掌握Go语言中的并发数据处理管道模式
- [ ] 能够设计和实现高性能的并发API服务器
- [ ] 理解实时数据处理系统的并发设计
- [ ] 掌握分布式任务系统的关键组件和实现方法
- [ ] 能够处理并发系统中的错误和资源管理
- [ ] 能够应用适当的并发模式解决实际问题

---

通过这些实战案例，您可以深入理解Go语言并发编程的应用场景和最佳实践。每个案例都展示了特定领域中并发编程的优势和实现技巧，帮助您将理论知识应用到实际项目中。记住，并发程序的设计需要仔细考虑资源管理、错误处理和优雅退出等方面，以构建健壮、高效的系统。
