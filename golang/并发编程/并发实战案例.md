# Goè¯­è¨€å¹¶å‘å®æˆ˜æ¡ˆä¾‹

## ğŸ“š å­¦ä¹ ç›®æ ‡
é€šè¿‡å®é™…æ¡ˆä¾‹æŒæ¡Goè¯­è¨€å¹¶å‘ç¼–ç¨‹åœ¨çœŸå®é¡¹ç›®ä¸­çš„åº”ç”¨ï¼Œç†è§£å¦‚ä½•è®¾è®¡å’Œå®ç°é«˜æ•ˆå¯é çš„å¹¶å‘ç³»ç»Ÿã€‚

---

## 1. å¹¶å‘ç½‘ç»œçˆ¬è™«

### 1.1 åŸºæœ¬æ¶æ„
```go
package main

import (
    "fmt"
    "io"
    "log"
    "net/http"
    "net/url"
    "os"
    "path/filepath"
    "strings"
    "sync"
    "time"

    "golang.org/x/net/html"
)

// çˆ¬è™«é…ç½®
type Crawler struct {
    baseURL      string
    depth        int
    maxGoroutine int
    visited      map[string]bool
    mutex        sync.Mutex
    wg           sync.WaitGroup
    semaphore    chan struct{}
}

// åˆ›å»ºæ–°çˆ¬è™«
func NewCrawler(baseURL string, depth, maxGoroutine int) *Crawler {
    return &Crawler{
        baseURL:      baseURL,
        depth:        depth,
        maxGoroutine: maxGoroutine,
        visited:      make(map[string]bool),
        semaphore:    make(chan struct{}, maxGoroutine),
    }
}

// å¼€å§‹çˆ¬å–
func (c *Crawler) Start() {
    fmt.Printf("å¼€å§‹çˆ¬å– %sï¼Œæœ€å¤§æ·±åº¦ %dï¼Œå¹¶å‘æ•° %d\n", c.baseURL, c.depth, c.maxGoroutine)
    startTime := time.Now()
    
    c.crawl(c.baseURL, 1)
    c.wg.Wait()
    
    elapsed := time.Since(startTime)
    fmt.Printf("çˆ¬å–å®Œæˆï¼Œè€—æ—¶ %vï¼Œè®¿é—®äº† %d ä¸ªURL\n", elapsed, len(c.visited))
}

// çˆ¬å–é¡µé¢
func (c *Crawler) crawl(urlStr string, depth int) {
    if depth > c.depth {
        return
    }
    
    // æ£€æŸ¥URLæ˜¯å¦å·²ç»è®¿é—®è¿‡
    c.mutex.Lock()
    if c.visited[urlStr] {
        c.mutex.Unlock()
        return
    }
    c.visited[urlStr] = true
    c.mutex.Unlock()
    
    // å¢åŠ ç­‰å¾…ç»„è®¡æ•°
    c.wg.Add(1)
    
    // å¹¶å‘çˆ¬å–
    go func() {
        defer c.wg.Done()
        
        // è·å–ä¿¡å·é‡
        c.semaphore <- struct{}{}
        defer func() { <-c.semaphore }()
        
        // è·å–é¡µé¢å†…å®¹
        fmt.Printf("çˆ¬å–: %s (æ·±åº¦: %d)\n", urlStr, depth)
        links, err := c.fetchLinks(urlStr)
        if err != nil {
            log.Printf("çˆ¬å– %s æ—¶å‡ºé”™: %v\n", urlStr, err)
            return
        }
        
        // é€’å½’çˆ¬å–é“¾æ¥
        for _, link := range links {
            c.crawl(link, depth+1)
        }
    }()
}

// è·å–é¡µé¢ä¸­çš„é“¾æ¥
func (c *Crawler) fetchLinks(urlStr string) ([]string, error) {
    resp, err := http.Get(urlStr)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("çŠ¶æ€ç : %d", resp.StatusCode)
    }
    
    // è§£æHTML
    doc, err := html.Parse(resp.Body)
    if err != nil {
        return nil, err
    }
    
    var links []string
    baseURL, err := url.Parse(urlStr)
    if err != nil {
        return nil, err
    }
    
    // æå–é“¾æ¥
    visitNode := func(n *html.Node) {
        if n.Type == html.ElementNode && n.Data == "a" {
            for _, a := range n.Attr {
                if a.Key == "href" {
                    link, err := resolveURL(baseURL, a.Val)
                    if err != nil {
                        continue
                    }
                    
                    // åªå¤„ç†åŒä¸€åŸŸåä¸‹çš„é“¾æ¥
                    if baseURL.Hostname() == link.Hostname() {
                        links = append(links, link.String())
                    }
                    break
                }
            }
        }
    }
    
    // éå†HTMLèŠ‚ç‚¹
    var traverse func(*html.Node)
    traverse = func(n *html.Node) {
        visitNode(n)
        for c := n.FirstChild; c != nil; c = c.NextSibling {
            traverse(c)
        }
    }
    traverse(doc)
    
    return links, nil
}

// è§£æURL
func resolveURL(base *url.URL, href string) (*url.URL, error) {
    link, err := url.Parse(href)
    if err != nil {
        return nil, err
    }
    return base.ResolveReference(link), nil
}

func main() {
    // åˆ›å»ºå¹¶å¯åŠ¨çˆ¬è™«
    crawler := NewCrawler("https://golang.org", 2, 10)
    crawler.Start()
}
```

### 1.2 æ·»åŠ ç»“æœå­˜å‚¨
```go
// æ·»åŠ åˆ°ä¸Šè¿°ä»£ç ä¸­

// é¡µé¢å†…å®¹å­˜å‚¨
type PageStore struct {
    baseDir string
    mutex   sync.Mutex
}

// åˆ›å»ºå­˜å‚¨
func NewPageStore(baseDir string) *PageStore {
    // ç¡®ä¿ç›®å½•å­˜åœ¨
    os.MkdirAll(baseDir, 0755)
    return &PageStore{
        baseDir: baseDir,
    }
}

// å­˜å‚¨é¡µé¢å†…å®¹
func (ps *PageStore) SavePage(pageURL string, content []byte) error {
    ps.mutex.Lock()
    defer ps.mutex.Unlock()
    
    // ç”Ÿæˆæ–‡ä»¶å
    parsedURL, err := url.Parse(pageURL)
    if err != nil {
        return err
    }
    
    // åˆ›å»ºè·¯å¾„
    path := parsedURL.Path
    if path == "" || path == "/" {
        path = "/index.html"
    } else if !strings.HasSuffix(path, ".html") {
        path = path + ".html"
    }
    
    // ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
    fullPath := filepath.Join(ps.baseDir, parsedURL.Hostname(), path)
    dir := filepath.Dir(fullPath)
    if err := os.MkdirAll(dir, 0755); err != nil {
        return err
    }
    
    // å†™å…¥æ–‡ä»¶
    return os.WriteFile(fullPath, content, 0644)
}

// ä¿®æ”¹çˆ¬è™«ç»“æ„
type Crawler struct {
    // ... åŸæœ‰å­—æ®µ ...
    store       *PageStore
}

// ä¿®æ”¹æ„é€ å‡½æ•°
func NewCrawler(baseURL string, depth, maxGoroutine int) *Crawler {
    return &Crawler{
        baseURL:      baseURL,
        depth:        depth,
        maxGoroutine: maxGoroutine,
        visited:      make(map[string]bool),
        semaphore:    make(chan struct{}, maxGoroutine),
        store:        NewPageStore("./crawled_pages"),
    }
}

// ä¿®æ”¹fetchLinkså‡½æ•°ä»¥ä¿å­˜å†…å®¹
func (c *Crawler) fetchLinks(urlStr string) ([]string, error) {
    resp, err := http.Get(urlStr)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("çŠ¶æ€ç : %d", resp.StatusCode)
    }
    
    // è¯»å–å†…å®¹
    content, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, err
    }
    
    // ä¿å­˜é¡µé¢
    if err := c.store.SavePage(urlStr, content); err != nil {
        log.Printf("ä¿å­˜é¡µé¢ %s å¤±è´¥: %v\n", urlStr, err)
    }
    
    // é‡ç½®å“åº”ä½“
    resp.Body = io.NopCloser(strings.NewReader(string(content)))
    
    // ... åŸæœ‰çš„HTMLè§£æä»£ç  ...
}
```

---

## 2. å¹¶å‘æ•°æ®å¤„ç†ç®¡é“

### 2.1 CSVæ•°æ®å¤„ç†ç®¡é“
```go
package main

import (
    "encoding/csv"
    "fmt"
    "io"
    "log"
    "os"
    "strconv"
    "sync"
    "time"
)

// æ•°æ®ç»“æ„
type Record struct {
    ID     int
    Name   string
    Value  float64
    Status string
}

// é˜¶æ®µ1: è¯»å–CSVè®°å½•
func recordGenerator(filename string) (<-chan Record, <-chan error, func()) {
    records := make(chan Record)
    errc := make(chan error, 1)
    done := make(chan struct{})
    
    go func() {
        defer close(records)
        defer close(errc)
        
        file, err := os.Open(filename)
        if err != nil {
            errc <- err
            return
        }
        defer file.Close()
        
        reader := csv.NewReader(file)
        // è·³è¿‡æ ‡é¢˜è¡Œ
        _, err = reader.Read()
        if err != nil {
            errc <- err
            return
        }
        
        for {
            select {
            case <-done:
                return
            default:
                row, err := reader.Read()
                if err == io.EOF {
                    return
                }
                if err != nil {
                    errc <- err
                    return
                }
                
                // è§£ææ•°æ®
                id, err := strconv.Atoi(row[0])
                if err != nil {
                    log.Printf("è§£æIDé”™è¯¯: %v", err)
                    continue
                }
                
                value, err := strconv.ParseFloat(row[2], 64)
                if err != nil {
                    log.Printf("è§£æValueé”™è¯¯: %v", err)
                    continue
                }
                
                // åˆ›å»ºè®°å½•
                record := Record{
                    ID:     id,
                    Name:   row[1],
                    Value:  value,
                    Status: row[3],
                }
                
                records <- record
            }
        }
    }()
    
    // è¿”å›å–æ¶ˆå‡½æ•°
    cancel := func() {
        close(done)
    }
    
    return records, errc, cancel
}

// é˜¶æ®µ2: æ•°æ®è½¬æ¢
func dataTransformer(in <-chan Record) <-chan Record {
    out := make(chan Record)
    
    go func() {
        defer close(out)
        for record := range in {
            // è½¬æ¢å€¼
            record.Value = record.Value * 1.1 // å¢åŠ 10%
            
            // ä¿®æ”¹çŠ¶æ€
            if record.Value > 1000 {
                record.Status = "High"
            } else if record.Value > 500 {
                record.Status = "Medium"
            } else {
                record.Status = "Low"
            }
            
            out <- record
        }
    }()
    
    return out
}

// é˜¶æ®µ3: è¿‡æ»¤è®°å½•
func recordFilter(in <-chan Record, condition func(Record) bool) <-chan Record {
    out := make(chan Record)
    
    go func() {
        defer close(out)
        for record := range in {
            if condition(record) {
                out <- record
            }
        }
    }()
    
    return out
}

// é˜¶æ®µ4: è®°å½•æ±‡æ€»
func recordAggregator(in <-chan Record) <-chan map[string]float64 {
    out := make(chan map[string]float64)
    
    go func() {
        defer close(out)
        
        totals := make(map[string]float64)
        
        for record := range in {
            totals[record.Status] += record.Value
        }
        
        out <- totals
    }()
    
    return out
}

// é˜¶æ®µ5: å¹¶è¡Œæ•°æ®å¤„ç†
func parallelProcessor(in <-chan Record, numWorkers int, processorFunc func(Record) Record) <-chan Record {
    out := make(chan Record)
    
    var wg sync.WaitGroup
    wg.Add(numWorkers)
    
    // å¯åŠ¨å¤šä¸ªå·¥ä½œè€…
    for i := 0; i < numWorkers; i++ {
        go func() {
            defer wg.Done()
            for record := range in {
                processed := processorFunc(record)
                out <- processed
            }
        }()
    }
    
    // å½“æ‰€æœ‰å·¥ä½œè€…å®Œæˆåå…³é—­è¾“å‡ºé€šé“
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

func main() {
    // åˆ›å»ºæµ‹è¯•CSVæ–‡ä»¶
    createTestCSV("test_data.csv", 10000)
    
    start := time.Now()
    
    // é˜¶æ®µ1: è¯»å–è®°å½•
    records, errc, cancel := recordGenerator("test_data.csv")
    defer cancel()
    
    // é˜¶æ®µ2: å¹¶è¡Œå¤„ç†è®°å½•
    processor := func(r Record) Record {
        // æ¨¡æ‹Ÿå¤æ‚å¤„ç†
        time.Sleep(time.Millisecond)
        r.Value = r.Value * 1.1
        return r
    }
    processedRecords := parallelProcessor(records, 4, processor)
    
    // é˜¶æ®µ3: è¿‡æ»¤è®°å½•
    filter := func(r Record) bool {
        return r.Value > 200
    }
    filteredRecords := recordFilter(processedRecords, filter)
    
    // é˜¶æ®µ4: æ±‡æ€»ç»“æœ
    resultChan := recordAggregator(filteredRecords)
    
    // å¤„ç†é”™è¯¯
    go func() {
        for err := range errc {
            log.Printf("å¤„ç†é”™è¯¯: %v", err)
        }
    }()
    
    // è·å–ç»“æœ
    result := <-resultChan
    
    // è¾“å‡ºç»“æœ
    fmt.Println("å¤„ç†ç»“æœ:")
    for status, total := range result {
        fmt.Printf("çŠ¶æ€ %s: æ€»å€¼ %.2f\n", status, total)
    }
    
    fmt.Printf("å¤„ç†æ—¶é—´: %v\n", time.Since(start))
}

// åˆ›å»ºæµ‹è¯•æ•°æ®
func createTestCSV(filename string, numRecords int) {
    file, err := os.Create(filename)
    if err != nil {
        log.Fatalf("åˆ›å»ºæµ‹è¯•æ–‡ä»¶å¤±è´¥: %v", err)
    }
    defer file.Close()
    
    writer := csv.NewWriter(file)
    defer writer.Flush()
    
    // å†™å…¥æ ‡é¢˜
    writer.Write([]string{"ID", "Name", "Value", "Status"})
    
    // å†™å…¥æ•°æ®
    for i := 1; i <= numRecords; i++ {
        value := strconv.FormatFloat(float64(i%1000), 'f', 2, 64)
        status := "Active"
        if i%5 == 0 {
            status = "Inactive"
        }
        
        writer.Write([]string{
            strconv.Itoa(i),
            fmt.Sprintf("Item %d", i),
            value,
            status,
        })
    }
}
```

---

## 3. å¹¶å‘APIæœåŠ¡å™¨

### 3.1 åŸºæœ¬ç»“æ„
```go
package main

import (
    "context"
    "encoding/json"
    "log"
    "net/http"
    "os"
    "os/signal"
    "sync"
    "syscall"
    "time"
)

// æ•°æ®ç±»å‹
type Item struct {
    ID    int    `json:"id"`
    Name  string `json:"name"`
    Value int    `json:"value"`
}

// æ•°æ®å­˜å‚¨
type ItemStore struct {
    items map[int]Item
    mutex sync.RWMutex
}

// åˆ›å»ºå­˜å‚¨
func NewItemStore() *ItemStore {
    return &ItemStore{
        items: make(map[int]Item),
    }
}

// è·å–é¡¹ç›®
func (s *ItemStore) GetItem(id int) (Item, bool) {
    s.mutex.RLock()
    defer s.mutex.RUnlock()
    
    item, exists := s.items[id]
    return item, exists
}

// è·å–æ‰€æœ‰é¡¹ç›®
func (s *ItemStore) GetAllItems() []Item {
    s.mutex.RLock()
    defer s.mutex.RUnlock()
    
    result := make([]Item, 0, len(s.items))
    for _, item := range s.items {
        result = append(result, item)
    }
    
    return result
}

// æ·»åŠ æˆ–æ›´æ–°é¡¹ç›®
func (s *ItemStore) SetItem(item Item) {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    s.items[item.ID] = item
}

// åˆ é™¤é¡¹ç›®
func (s *ItemStore) DeleteItem(id int) {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    delete(s.items, id)
}

// å¤„ç†å‡½æ•°
type APIHandler struct {
    store *ItemStore
}

// å¤„ç†æ‰€æœ‰é¡¹ç›®
func (h *APIHandler) handleItems(w http.ResponseWriter, r *http.Request) {
    switch r.Method {
    case http.MethodGet:
        // è·å–æ‰€æœ‰é¡¹ç›®
        items := h.store.GetAllItems()
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "items": items,
        })
        
    case http.MethodPost:
        // æ·»åŠ é¡¹ç›®
        var item Item
        if err := json.NewDecoder(r.Body).Decode(&item); err != nil {
            http.Error(w, "Invalid request body", http.StatusBadRequest)
            return
        }
        
        h.store.SetItem(item)
        
        w.Header().Set("Content-Type", "application/json")
        w.WriteHeader(http.StatusCreated)
        json.NewEncoder(w).Encode(map[string]interface{}{
            "message": "Item created",
            "item":    item,
        })
        
    default:
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
    }
}

// å¤„ç†å•ä¸ªé¡¹ç›®
func (h *APIHandler) handleItem(w http.ResponseWriter, r *http.Request) {
    // ä»URLæå–ID
    id := 0 // åœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä»URLè·¯å¾„è§£æ
    
    switch r.Method {
    case http.MethodGet:
        // è·å–é¡¹ç›®
        item, exists := h.store.GetItem(id)
        if !exists {
            http.Error(w, "Item not found", http.StatusNotFound)
            return
        }
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(item)
        
    case http.MethodPut:
        // æ›´æ–°é¡¹ç›®
        var item Item
        if err := json.NewDecoder(r.Body).Decode(&item); err != nil {
            http.Error(w, "Invalid request body", http.StatusBadRequest)
            return
        }
        
        item.ID = id
        h.store.SetItem(item)
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "message": "Item updated",
            "item":    item,
        })
        
    case http.MethodDelete:
        // åˆ é™¤é¡¹ç›®
        h.store.DeleteItem(id)
        
        w.Header().Set("Content-Type", "application/json")
        json.NewEncoder(w).Encode(map[string]interface{}{
            "message": "Item deleted",
        })
        
    default:
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
    }
}

func main() {
    // åˆ›å»ºæ•°æ®å­˜å‚¨
    store := NewItemStore()
    handler := &APIHandler{store: store}
    
    // è®¾ç½®å¤„ç†å‡½æ•°
    mux := http.NewServeMux()
    mux.HandleFunc("/api/items", handler.handleItems)
    mux.HandleFunc("/api/items/", handler.handleItem)
    
    // åˆ›å»ºæœåŠ¡å™¨
    server := &http.Server{
        Addr:    ":8080",
        Handler: mux,
    }
    
    // ä¼˜é›…å…³é—­é€šé“
    done := make(chan bool, 1)
    quit := make(chan os.Signal, 1)
    signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)
    
    // å¯åŠ¨æœåŠ¡å™¨
    go func() {
        log.Println("æœåŠ¡å™¨å¯åŠ¨åœ¨ :8080")
        if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
            log.Fatalf("å¯åŠ¨æœåŠ¡å™¨é”™è¯¯: %v", err)
        }
    }()
    
    // ç›‘å¬å…³é—­ä¿¡å·
    go func() {
        <-quit
        log.Println("æœåŠ¡å™¨å…³é—­ä¸­...")
        
        // åˆ›å»ºè¶…æ—¶ä¸Šä¸‹æ–‡
        ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()
        
        // å…³é—­æœåŠ¡å™¨
        if err := server.Shutdown(ctx); err != nil {
            log.Fatalf("æœåŠ¡å™¨å…³é—­é”™è¯¯: %v", err)
        }
        
        close(done)
    }()
    
    <-done
    log.Println("æœåŠ¡å™¨å·²åœæ­¢")
}
```

### 3.2 æ·»åŠ ç¼“å­˜å’Œé™æµ
```go
// åœ¨ä¸Šè¿°ä»£ç åŸºç¡€ä¸Šæ·»åŠ 

import (
    "golang.org/x/time/rate"
    "sync"
    "time"
)

// æ·»åŠ ç¼“å­˜
type Cache struct {
    items      map[string]cacheItem
    mutex      sync.RWMutex
    expiration time.Duration
}

type cacheItem struct {
    value      []byte
    expiration time.Time
}

// åˆ›å»ºç¼“å­˜
func NewCache(expiration time.Duration) *Cache {
    cache := &Cache{
        items:      make(map[string]cacheItem),
        expiration: expiration,
    }
    
    // å®šæœŸæ¸…ç†è¿‡æœŸé¡¹
    go cache.startCleanup()
    
    return cache
}

// è®¾ç½®ç¼“å­˜é¡¹
func (c *Cache) Set(key string, value []byte) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    c.items[key] = cacheItem{
        value:      value,
        expiration: time.Now().Add(c.expiration),
    }
}

// è·å–ç¼“å­˜é¡¹
func (c *Cache) Get(key string) ([]byte, bool) {
    c.mutex.RLock()
    defer c.mutex.RUnlock()
    
    item, found := c.items[key]
    if !found {
        return nil, false
    }
    
    // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
    if time.Now().After(item.expiration) {
        return nil, false
    }
    
    return item.value, true
}

// åˆ é™¤ç¼“å­˜é¡¹
func (c *Cache) Delete(key string) {
    c.mutex.Lock()
    defer c.mutex.Unlock()
    
    delete(c.items, key)
}

// æ¸…ç†è¿‡æœŸé¡¹
func (c *Cache) startCleanup() {
    ticker := time.NewTicker(time.Minute)
    defer ticker.Stop()
    
    for range ticker.C {
        c.mutex.Lock()
        
        now := time.Now()
        for key, item := range c.items {
            if now.After(item.expiration) {
                delete(c.items, key)
            }
        }
        
        c.mutex.Unlock()
    }
}

// é™æµä¸­é—´ä»¶
type RateLimiter struct {
    limiter *rate.Limiter
}

func NewRateLimiter(rps float64, burst int) *RateLimiter {
    return &RateLimiter{
        limiter: rate.NewLimiter(rate.Limit(rps), burst),
    }
}

func (rl *RateLimiter) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        if !rl.limiter.Allow() {
            http.Error(w, "Too many requests", http.StatusTooManyRequests)
            return
        }
        next.ServeHTTP(w, r)
    })
}

// ç¼“å­˜ä¸­é—´ä»¶
type CacheMiddleware struct {
    cache *Cache
}

func NewCacheMiddleware(expiration time.Duration) *CacheMiddleware {
    return &CacheMiddleware{
        cache: NewCache(expiration),
    }
}

func (cm *CacheMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // åªç¼“å­˜GETè¯·æ±‚
        if r.Method != http.MethodGet {
            next.ServeHTTP(w, r)
            return
        }
        
        // ä½¿ç”¨URLä½œä¸ºç¼“å­˜é”®
        key := r.URL.String()
        
        // æŸ¥æ‰¾ç¼“å­˜
        if cached, found := cm.cache.Get(key); found {
            w.Header().Set("Content-Type", "application/json")
            w.Header().Set("X-Cache", "HIT")
            w.Write(cached)
            return
        }
        
        // è‡ªå®šä¹‰å“åº”å†™å…¥å™¨ä»¥æ•è·å“åº”
        crw := &cacheResponseWriter{
            ResponseWriter: w,
            statusCode:     http.StatusOK,
            body:           &bytes.Buffer{},
        }
        
        // è°ƒç”¨ä¸‹ä¸€ä¸ªå¤„ç†å™¨
        next.ServeHTTP(crw, r)
        
        // åªç¼“å­˜æˆåŠŸå“åº”
        if crw.statusCode == http.StatusOK {
            cm.cache.Set(key, crw.body.Bytes())
        }
    })
}

// ç¼“å­˜å“åº”å†™å…¥å™¨
type cacheResponseWriter struct {
    http.ResponseWriter
    statusCode int
    body       *bytes.Buffer
}

func (crw *cacheResponseWriter) WriteHeader(statusCode int) {
    crw.statusCode = statusCode
    crw.ResponseWriter.WriteHeader(statusCode)
}

func (crw *cacheResponseWriter) Write(b []byte) (int, error) {
    crw.body.Write(b)
    return crw.ResponseWriter.Write(b)
}

// åœ¨mainå‡½æ•°ä¸­åº”ç”¨ä¸­é—´ä»¶
func main() {
    // ... åŸæœ‰ä»£ç  ...
    
    // åˆ›å»ºä¸­é—´ä»¶
    rateLimiter := NewRateLimiter(100, 50) // é™åˆ¶æ¯ç§’100ä¸ªè¯·æ±‚ï¼Œçªå‘50ä¸ª
    cacheMiddleware := NewCacheMiddleware(5 * time.Minute) // ç¼“å­˜5åˆ†é’Ÿ
    
    // è®¾ç½®å¤„ç†å‡½æ•°
    mux := http.NewServeMux()
    mux.HandleFunc("/api/items", handler.handleItems)
    mux.HandleFunc("/api/items/", handler.handleItem)
    
    // åº”ç”¨ä¸­é—´ä»¶
    var handler http.Handler = mux
    handler = rateLimiter.Middleware(handler)
    handler = cacheMiddleware.Middleware(handler)
    
    // åˆ›å»ºæœåŠ¡å™¨
    server := &http.Server{
        Addr:    ":8080",
        Handler: handler,
    }
    
    // ... åŸæœ‰ä»£ç  ...
}
```

---

## 4. å®æ—¶æ•°æ®å¤„ç†ç³»ç»Ÿ

### 4.1 ä½¿ç”¨Channelæ„å»ºæ•°æ®æµæ°´çº¿
```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "math/rand"
    "os"
    "os/signal"
    "sync"
    "syscall"
    "time"
)

// æ•°æ®ç»“æ„
type SensorData struct {
    ID        string    `json:"id"`
    Type      string    `json:"type"`
    Value     float64   `json:"value"`
    Timestamp time.Time `json:"timestamp"`
}

// ç»“æœç»“æ„
type ProcessedData struct {
    SensorID    string  `json:"sensor_id"`
    SensorType  string  `json:"sensor_type"`
    AverageValue float64 `json:"average_value"`
    MinValue    float64 `json:"min_value"`
    MaxValue    float64 `json:"max_value"`
    Count       int     `json:"count"`
    Window      string  `json:"window"`
}

// æ•°æ®ç”Ÿæˆå™¨
func generateData(ctx context.Context, rate int) <-chan SensorData {
    out := make(chan SensorData)
    
    go func() {
        defer close(out)
        
        ticker := time.NewTicker(time.Second / time.Duration(rate))
        defer ticker.Stop()
        
        sensorTypes := []string{"temperature", "humidity", "pressure", "light"}
        sensorCount := 10
        
        for {
            select {
            case <-ctx.Done():
                return
            case <-ticker.C:
                // ç”Ÿæˆéšæœºä¼ æ„Ÿå™¨æ•°æ®
                sensorID := fmt.Sprintf("sensor-%d", rand.Intn(sensorCount))
                sensorType := sensorTypes[rand.Intn(len(sensorTypes))]
                
                // æ ¹æ®ä¼ æ„Ÿå™¨ç±»å‹ç”Ÿæˆåˆç†çš„å€¼
                var value float64
                switch sensorType {
                case "temperature":
                    value = 20 + rand.Float64()*10 // 20-30Â°C
                case "humidity":
                    value = 30 + rand.Float64()*50 // 30-80%
                case "pressure":
                    value = 980 + rand.Float64()*40 // 980-1020 hPa
                case "light":
                    value = rand.Float64() * 1000 // 0-1000 lux
                }
                
                data := SensorData{
                    ID:        sensorID,
                    Type:      sensorType,
                    Value:     value,
                    Timestamp: time.Now(),
                }
                
                out <- data
            }
        }
    }()
    
    return out
}

// æ•°æ®è¿‡æ»¤å™¨
func filterData(ctx context.Context, in <-chan SensorData, filterFn func(SensorData) bool) <-chan SensorData {
    out := make(chan SensorData)
    
    go func() {
        defer close(out)
        
        for {
            select {
            case <-ctx.Done():
                return
            case data, ok := <-in:
                if !ok {
                    return
                }
                
                if filterFn(data) {
                    out <- data
                }
            }
        }
    }()
    
    return out
}

// æ•°æ®çª—å£èšåˆ
func windowedAggregation(ctx context.Context, in <-chan SensorData, windowSize time.Duration) <-chan ProcessedData {
    out := make(chan ProcessedData)
    
    go func() {
        defer close(out)
        
        // ä¿å­˜æ¯ä¸ªä¼ æ„Ÿå™¨çš„æ•°æ®
        type sensorStats struct {
            values   []float64
            count    int
            sum      float64
            min      float64
            max      float64
            lastSent time.Time
        }
        
        stats := make(map[string]*sensorStats)
        ticker := time.NewTicker(windowSize)
        defer ticker.Stop()
        
        for {
            select {
            case <-ctx.Done():
                return
            case data, ok := <-in:
                if !ok {
                    return
                }
                
                // ä¸ºä¼ æ„Ÿå™¨åˆ›å»ºç»Ÿè®¡ä¿¡æ¯
                key := data.ID + "-" + data.Type
                if _, exists := stats[key]; !exists {
                    stats[key] = &sensorStats{
                        values:   make([]float64, 0),
                        min:      data.Value,
                        max:      data.Value,
                        lastSent: time.Now(),
                    }
                }
                
                s := stats[key]
                s.values = append(s.values, data.Value)
                s.count++
                s.sum += data.Value
                
                // æ›´æ–°æœ€å°å€¼å’Œæœ€å¤§å€¼
                if data.Value < s.min {
                    s.min = data.Value
                }
                if data.Value > s.max {
                    s.max = data.Value
                }
                
            case <-ticker.C:
                // å‘é€æ‰€æœ‰ä¼ æ„Ÿå™¨çš„èšåˆæ•°æ®
                now := time.Now()
                windowStr := fmt.Sprintf("%s - %s", now.Add(-windowSize).Format(time.RFC3339), now.Format(time.RFC3339))
                
                for key, s := range stats {
                    if s.count == 0 {
                        continue
                    }
                    
                    // è§£æIDå’Œç±»å‹
                    parts := strings.Split(key, "-")
                    sensorID := parts[0]
                    sensorType := parts[1]
                    
                    // åˆ›å»ºå¤„ç†åçš„æ•°æ®
                    processed := ProcessedData{
                        SensorID:     sensorID,
                        SensorType:   sensorType,
                        AverageValue: s.sum / float64(s.count),
                        MinValue:     s.min,
                        MaxValue:     s.max,
                        Count:        s.count,
                        Window:       windowStr,
                    }
                    
                    // å‘é€ç»“æœ
                    out <- processed
                    
                    // é‡ç½®ç»Ÿè®¡ä¿¡æ¯
                    stats[key] = &sensorStats{
                        values:   make([]float64, 0),
                        min:      math.MaxFloat64,
                        max:      -math.MaxFloat64,
                        lastSent: now,
                    }
                }
            }
        }
    }()
    
    return out
}

// æ•°æ®æŒä¹…åŒ–
func persistData(ctx context.Context, in <-chan ProcessedData) {
    // æ‰“å¼€æˆ–åˆ›å»ºè¾“å‡ºæ–‡ä»¶
    file, err := os.OpenFile("sensor_data.json", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
    if err != nil {
        log.Fatalf("åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤±è´¥: %v", err)
    }
    defer file.Close()
    
    encoder := json.NewEncoder(file)
    
    for {
        select {
        case <-ctx.Done():
            return
        case data, ok := <-in:
            if !ok {
                return
            }
            
            // å†™å…¥æ–‡ä»¶
            if err := encoder.Encode(data); err != nil {
                log.Printf("å†™å…¥æ•°æ®å¤±è´¥: %v", err)
            }
            
            // ä¹Ÿè¾“å‡ºåˆ°æ§åˆ¶å°
            fmt.Printf("å¤„ç†æ•°æ®: %s (%s) - å¹³å‡å€¼: %.2f, æœ€å°å€¼: %.2f, æœ€å¤§å€¼: %.2f, æ•°é‡: %d\n",
                data.SensorID, data.SensorType, data.AverageValue, data.MinValue, data.MaxValue, data.Count)
        }
    }
}

func main() {
    // è®¾ç½®éšæœºæ•°ç§å­
    rand.Seed(time.Now().UnixNano())
    
    // åˆ›å»ºå–æ¶ˆä¸Šä¸‹æ–‡
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    // æ„å»ºæ•°æ®æµæ°´çº¿
    rawData := generateData(ctx, 50) // æ¯ç§’ç”Ÿæˆ50ä¸ªæ•°æ®ç‚¹
    
    // è¿‡æ»¤æ— æ•ˆæ•°æ®
    validData := filterData(ctx, rawData, func(data SensorData) bool {
        // ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥
        switch data.Type {
        case "temperature":
            return data.Value >= -30 && data.Value <= 50
        case "humidity":
            return data.Value >= 0 && data.Value <= 100
        case "pressure":
            return data.Value >= 900 && data.Value <= 1100
        case "light":
            return data.Value >= 0 && data.Value <= 2000
        default:
            return false
        }
    })
    
    // èšåˆæ•°æ®
    aggregatedData := windowedAggregation(ctx, validData, 5*time.Second) // 5ç§’çª—å£
    
    // å¯åŠ¨æŒä¹…åŒ–åç¨‹
    go persistData(ctx, aggregatedData)
    
    // ç­‰å¾…ä¸­æ–­ä¿¡å·
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
    
    fmt.Println("å®æ—¶æ•°æ®å¤„ç†ç³»ç»Ÿå¯åŠ¨ã€‚æŒ‰Ctrl+Cåœæ­¢...")
    <-sigChan
    
    fmt.Println("\næ­£åœ¨åœæ­¢...")
    cancel()
    time.Sleep(time.Second) // ç»™goroutinesæ—¶é—´æ¸…ç†
    fmt.Println("å·²åœæ­¢")
}
```

---

## 5. åˆ†å¸ƒå¼ä»»åŠ¡ç³»ç»Ÿ

### 5.1 Workerä»»åŠ¡å¤„ç†æ¡†æ¶
```go
package main

import (
    "context"
    "encoding/json"
    "fmt"
    "log"
    "math/rand"
    "sync"
    "time"
)

// ä»»åŠ¡å®šä¹‰
type Task struct {
    ID        string          `json:"id"`
    Type      string          `json:"type"`
    Data      json.RawMessage `json:"data"`
    CreatedAt time.Time       `json:"created_at"`
    Status    string          `json:"status"`
    Result    interface{}     `json:"result,omitempty"`
    Error     string          `json:"error,omitempty"`
}

// ä»»åŠ¡å¤„ç†æ¥å£
type TaskProcessor interface {
    ProcessTask(ctx context.Context, task Task) (interface{}, error)
}

// ä»»åŠ¡å¤„ç†å™¨æ˜ å°„
var processors = make(map[string]TaskProcessor)

// æ³¨å†Œä»»åŠ¡å¤„ç†å™¨
func RegisterProcessor(taskType string, processor TaskProcessor) {
    processors[taskType] = processor
}

// ä»»åŠ¡é˜Ÿåˆ—
type TaskQueue struct {
    tasks  chan Task
    closed bool
    mutex  sync.RWMutex
}

// åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
func NewTaskQueue(capacity int) *TaskQueue {
    return &TaskQueue{
        tasks: make(chan Task, capacity),
    }
}

// æ·»åŠ ä»»åŠ¡
func (q *TaskQueue) AddTask(task Task) error {
    q.mutex.RLock()
    defer q.mutex.RUnlock()
    
    if q.closed {
        return fmt.Errorf("task queue is closed")
    }
    
    q.tasks <- task
    return nil
}

// å…³é—­é˜Ÿåˆ—
func (q *TaskQueue) Close() {
    q.mutex.Lock()
    defer q.mutex.Unlock()
    
    if !q.closed {
        q.closed = true
        close(q.tasks)
    }
}

// ä»»åŠ¡ç»“æœå­˜å‚¨
type TaskResultStore interface {
    SaveResult(task Task) error
    GetTaskByID(id string) (Task, error)
}

// å†…å­˜ä»»åŠ¡ç»“æœå­˜å‚¨
type MemoryTaskStore struct {
    tasks map[string]Task
    mutex sync.RWMutex
}

// åˆ›å»ºå†…å­˜ä»»åŠ¡å­˜å‚¨
func NewMemoryTaskStore() *MemoryTaskStore {
    return &MemoryTaskStore{
        tasks: make(map[string]Task),
    }
}

// ä¿å­˜ä»»åŠ¡ç»“æœ
func (s *MemoryTaskStore) SaveResult(task Task) error {
    s.mutex.Lock()
    defer s.mutex.Unlock()
    
    s.tasks[task.ID] = task
    return nil
}

// è·å–ä»»åŠ¡
func (s *MemoryTaskStore) GetTaskByID(id string) (Task, error) {
    s.mutex.RLock()
    defer s.mutex.RUnlock()
    
    task, exists := s.tasks[id]
    if !exists {
        return Task{}, fmt.Errorf("task with ID %s not found", id)
    }
    
    return task, nil
}

// å·¥ä½œè€…
type Worker struct {
    id       int
    queue    *TaskQueue
    store    TaskResultStore
    stopChan chan struct{}
    wg       *sync.WaitGroup
}

// åˆ›å»ºå·¥ä½œè€…
func NewWorker(id int, queue *TaskQueue, store TaskResultStore, wg *sync.WaitGroup) *Worker {
    return &Worker{
        id:       id,
        queue:    queue,
        store:    store,
        stopChan: make(chan struct{}),
        wg:       wg,
    }
}

// å¯åŠ¨å·¥ä½œè€…
func (w *Worker) Start() {
    w.wg.Add(1)
    go w.run()
}

// åœæ­¢å·¥ä½œè€…
func (w *Worker) Stop() {
    close(w.stopChan)
}

// å·¥ä½œè€…ä¸»å¾ªç¯
func (w *Worker) run() {
    defer w.wg.Done()
    
    log.Printf("Worker %d started", w.id)
    
    for {
        select {
        case <-w.stopChan:
            log.Printf("Worker %d stopping", w.id)
            return
        case task, ok := <-w.queue.tasks:
            if !ok {
                log.Printf("Worker %d: queue closed", w.id)
                return
            }
            
            w.processTask(task)
        }
    }
}

// å¤„ç†ä»»åŠ¡
func (w *Worker) processTask(task Task) {
    log.Printf("Worker %d processing task %s of type %s", w.id, task.ID, task.Type)
    
    // æ›´æ–°ä»»åŠ¡çŠ¶æ€
    task.Status = "processing"
    w.store.SaveResult(task)
    
    // åˆ›å»ºä¸Šä¸‹æ–‡
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    // è·å–å¤„ç†å™¨
    processor, exists := processors[task.Type]
    if !exists {
        task.Status = "failed"
        task.Error = fmt.Sprintf("no processor found for task type %s", task.Type)
        w.store.SaveResult(task)
        log.Printf("Worker %d: %s", w.id, task.Error)
        return
    }
    
    // å¤„ç†ä»»åŠ¡
    result, err := processor.ProcessTask(ctx, task)
    
    // æ›´æ–°ä»»åŠ¡çŠ¶æ€
    if err != nil {
        task.Status = "failed"
        task.Error = err.Error()
    } else {
        task.Status = "completed"
        task.Result = result
    }
    
    // ä¿å­˜ç»“æœ
    w.store.SaveResult(task)
    
    log.Printf("Worker %d completed task %s with status %s", w.id, task.ID, task.Status)
}

// ç®€å•æ•°å­¦ä»»åŠ¡å¤„ç†å™¨
type MathTaskProcessor struct{}

func (p *MathTaskProcessor) ProcessTask(ctx context.Context, task Task) (interface{}, error) {
    // è§£æä»»åŠ¡æ•°æ®
    var data struct {
        Operation string  `json:"operation"`
        A         float64 `json:"a"`
        B         float64 `json:"b"`
    }
    
    if err := json.Unmarshal(task.Data, &data); err != nil {
        return nil, fmt.Errorf("invalid task data: %v", err)
    }
    
    // æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    processingTime := time.Duration(rand.Intn(3000)) * time.Millisecond
    
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    case <-time.After(processingTime):
        // å¤„ç†ä¸åŒæ“ä½œ
        switch data.Operation {
        case "add":
            return data.A + data.B, nil
        case "subtract":
            return data.A - data.B, nil
        case "multiply":
            return data.A * data.B, nil
        case "divide":
            if data.B == 0 {
                return nil, fmt.Errorf("division by zero")
            }
            return data.A / data.B, nil
        default:
            return nil, fmt.Errorf("unknown operation: %s", data.Operation)
        }
    }
}

// ä¸»å‡½æ•°
func main() {
    // è®¾ç½®éšæœºæ•°ç§å­
    rand.Seed(time.Now().UnixNano())
    
    // æ³¨å†Œä»»åŠ¡å¤„ç†å™¨
    RegisterProcessor("math", &MathTaskProcessor{})
    
    // åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœå­˜å‚¨
    queue := NewTaskQueue(100)
    store := NewMemoryTaskStore()
    
    // åˆ›å»ºå·¥ä½œè€…æ± 
    var wg sync.WaitGroup
    numWorkers := 5
    workers := make([]*Worker, numWorkers)
    
    for i := 0; i < numWorkers; i++ {
        workers[i] = NewWorker(i+1, queue, store, &wg)
        workers[i].Start()
    }
    
    // åˆ›å»ºä¸€äº›ä»»åŠ¡
    operations := []string{"add", "subtract", "multiply", "divide"}
    
    for i := 0; i < 20; i++ {
        operation := operations[rand.Intn(len(operations))]
        
        taskData := struct {
            Operation string  `json:"operation"`
            A         float64 `json:"a"`
            B         float64 `json:"b"`
        }{
            Operation: operation,
            A:         float64(rand.Intn(100)),
            B:         float64(rand.Intn(10)),
        }
        
        data, _ := json.Marshal(taskData)
        
        task := Task{
            ID:        fmt.Sprintf("task-%d", i+1),
            Type:      "math",
            Data:      json.RawMessage(data),
            CreatedAt: time.Now(),
            Status:    "pending",
        }
        
        if err := queue.AddTask(task); err != nil {
            log.Printf("Failed to add task: %v", err)
            continue
        }
        
        log.Printf("Added task %s: %s %v %v", task.ID, taskData.Operation, taskData.A, taskData.B)
    }
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    time.Sleep(2 * time.Second)
    log.Println("Stopping workers...")
    
    // åœæ­¢å·¥ä½œè€…
    for _, worker := range workers {
        worker.Stop()
    }
    
    // å…³é—­é˜Ÿåˆ—
    queue.Close()
    
    // ç­‰å¾…æ‰€æœ‰å·¥ä½œè€…å®Œæˆ
    wg.Wait()
    
    // è¾“å‡ºä»»åŠ¡ç»“æœ
    log.Println("\nTask results:")
    for i := 0; i < 20; i++ {
        taskID := fmt.Sprintf("task-%d", i+1)
        task, err := store.GetTaskByID(taskID)
        if err != nil {
            log.Printf("Failed to get task %s: %v", taskID, err)
            continue
        }
        
        var taskData struct {
            Operation string  `json:"operation"`
            A         float64 `json:"a"`
            B         float64 `json:"b"`
        }
        json.Unmarshal(task.Data, &taskData)
        
        if task.Status == "completed" {
            log.Printf("Task %s: %v %s %v = %v", task.ID, taskData.A, taskData.Operation, taskData.B, task.Result)
        } else {
            log.Printf("Task %s: %v %s %v - %s: %s", task.ID, taskData.A, taskData.Operation, taskData.B, task.Status, task.Error)
        }
    }
}
```

---

## 6. å­¦ä¹ æ£€æŸ¥ç‚¹

- [ ] ç†è§£å¹¶å‘ç½‘ç»œçˆ¬è™«çš„è®¾è®¡åŸç†å’Œå®ç°
- [ ] æŒæ¡Goè¯­è¨€ä¸­çš„å¹¶å‘æ•°æ®å¤„ç†ç®¡é“æ¨¡å¼
- [ ] èƒ½å¤Ÿè®¾è®¡å’Œå®ç°é«˜æ€§èƒ½çš„å¹¶å‘APIæœåŠ¡å™¨
- [ ] ç†è§£å®æ—¶æ•°æ®å¤„ç†ç³»ç»Ÿçš„å¹¶å‘è®¾è®¡
- [ ] æŒæ¡åˆ†å¸ƒå¼ä»»åŠ¡ç³»ç»Ÿçš„å…³é”®ç»„ä»¶å’Œå®ç°æ–¹æ³•
- [ ] èƒ½å¤Ÿå¤„ç†å¹¶å‘ç³»ç»Ÿä¸­çš„é”™è¯¯å’Œèµ„æºç®¡ç†
- [ ] èƒ½å¤Ÿåº”ç”¨é€‚å½“çš„å¹¶å‘æ¨¡å¼è§£å†³å®é™…é—®é¢˜

---

é€šè¿‡è¿™äº›å®æˆ˜æ¡ˆä¾‹ï¼Œæ‚¨å¯ä»¥æ·±å…¥ç†è§£Goè¯­è¨€å¹¶å‘ç¼–ç¨‹çš„åº”ç”¨åœºæ™¯å’Œæœ€ä½³å®è·µã€‚æ¯ä¸ªæ¡ˆä¾‹éƒ½å±•ç¤ºäº†ç‰¹å®šé¢†åŸŸä¸­å¹¶å‘ç¼–ç¨‹çš„ä¼˜åŠ¿å’Œå®ç°æŠ€å·§ï¼Œå¸®åŠ©æ‚¨å°†ç†è®ºçŸ¥è¯†åº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­ã€‚è®°ä½ï¼Œå¹¶å‘ç¨‹åºçš„è®¾è®¡éœ€è¦ä»”ç»†è€ƒè™‘èµ„æºç®¡ç†ã€é”™è¯¯å¤„ç†å’Œä¼˜é›…é€€å‡ºç­‰æ–¹é¢ï¼Œä»¥æ„å»ºå¥å£®ã€é«˜æ•ˆçš„ç³»ç»Ÿã€‚
