# Go语言并发性能调优

## 📚 学习目标
掌握Go语言并发程序的性能分析、瓶颈识别和优化技术，能够构建高效、可扩展的并发系统。

---

## 1. 性能分析基础

### 1.1 使用pprof进行性能分析
```go
package main

import (
    "fmt"
    "log"
    "net/http"
    _ "net/http/pprof" // 引入pprof
    "runtime"
    "sync"
    "time"
)

func computeIntensive() {
    // 计算密集型任务
    for i := 0; i < 1000000; i++ {
        _ = i * i
    }
}

func memoryIntensive() {
    // 内存密集型任务
    data := make([]byte, 10*1024*1024) // 分配10MB内存
    for i := range data {
        data[i] = byte(i % 255)
    }
    _ = data
}

func simulateWorkload() {
    var wg sync.WaitGroup
    
    // 启动10个goroutine执行计算密集型任务
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            computeIntensive()
        }()
    }
    
    // 启动5个goroutine执行内存密集型任务
    for i := 0; i < 5; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            memoryIntensive()
        }()
    }
    
    wg.Wait()
}

func main() {
    // 启动pprof服务器
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
    
    fmt.Println("性能分析服务器启动在 http://localhost:6060/debug/pprof/")
    fmt.Println("按Ctrl+C退出")
    
    // 定期执行工作负载
    for {
        simulateWorkload()
        time.Sleep(500 * time.Millisecond)
    }
}
```

使用以下命令收集和分析性能数据：

```bash
# CPU分析
go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30

# 内存分析
go tool pprof http://localhost:6060/debug/pprof/heap

# 阻塞分析
go tool pprof http://localhost:6060/debug/pprof/block

# Goroutine分析
go tool pprof http://localhost:6060/debug/pprof/goroutine
```

### 1.2 使用trace工具进行分析
```go
package main

import (
    "context"
    "fmt"
    "os"
    "runtime/trace"
    "sync"
)

func main() {
    // 创建trace文件
    f, err := os.Create("trace.out")
    if err != nil {
        panic(err)
    }
    defer f.Close()
    
    // 开始记录trace
    err = trace.Start(f)
    if err != nil {
        panic(err)
    }
    defer trace.Stop()
    
    // 执行需要分析的代码
    var wg sync.WaitGroup
    
    // 创建一个任务
    ctx := context.Background()
    ctx, task := trace.NewTask(ctx, "main")
    defer task.End()
    
    // 启动10个goroutine
    for i := 0; i < 10; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            
            // 创建区域以便在trace中识别
            trace.WithRegion(ctx, fmt.Sprintf("worker-%d", id), func() {
                // 模拟工作
                sum := 0
                for i := 0; i < 1000000; i++ {
                    sum += i
                }
            })
        }(i)
    }
    
    wg.Wait()
    
    fmt.Println("Trace已记录到trace.out")
    fmt.Println("使用'go tool trace trace.out'查看")
}
```

使用以下命令查看trace：

```bash
go tool trace trace.out
```

---

## 2. 并发瓶颈识别

### 2.1 识别锁竞争
```go
package main

import (
    "fmt"
    "net/http"
    _ "net/http/pprof"
    "sync"
    "time"
)

var (
    counter int
    mutex   sync.Mutex
)

func highContentionIncrement() {
    for i := 0; i < 1000; i++ {
        mutex.Lock()
        counter++
        mutex.Unlock()
    }
}

func lowContentionIncrement() {
    // 批处理增加，减少锁竞争
    local := 0
    for i := 0; i < 1000; i++ {
        local++
    }
    
    // 只锁一次
    mutex.Lock()
    counter += local
    mutex.Unlock()
}

func main() {
    // 启动pprof
    go func() {
        fmt.Println("pprof服务启动在: http://localhost:6060/debug/pprof/")
        http.ListenAndServe("localhost:6060", nil)
    }()
    
    fmt.Println("开始高竞争测试...")
    
    var wg sync.WaitGroup
    start := time.Now()
    
    // 高竞争情况
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            highContentionIncrement()
        }()
    }
    
    wg.Wait()
    highDuration := time.Since(start)
    fmt.Printf("高竞争用时: %v, 计数器值: %d\n", highDuration, counter)
    
    // 重置计数器
    counter = 0
    
    fmt.Println("开始低竞争测试...")
    start = time.Now()
    
    // 低竞争情况
    for i := 0; i < 100; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            lowContentionIncrement()
        }()
    }
    
    wg.Wait()
    lowDuration := time.Since(start)
    fmt.Printf("低竞争用时: %v, 计数器值: %d\n", lowDuration, counter)
    fmt.Printf("性能提升: %.2f倍\n", float64(highDuration)/float64(lowDuration))
    
    fmt.Println("运行'go tool pprof http://localhost:6060/debug/pprof/mutex'分析锁竞争")
    select {} // 保持程序运行以便进行pprof分析
}
```

### 2.2 识别Channel瓶颈
```go
package main

import (
    "fmt"
    "net/http"
    _ "net/http/pprof"
    "sync"
    "time"
)

func unbufferedChannelTest() time.Duration {
    start := time.Now()
    ch := make(chan int) // 无缓冲通道
    
    var wg sync.WaitGroup
    wg.Add(2)
    
    // 发送者
    go func() {
        defer wg.Done()
        for i := 0; i < 10000; i++ {
            ch <- i // 每次发送都需要等待接收者准备好
        }
        close(ch)
    }()
    
    // 接收者
    go func() {
        defer wg.Done()
        for range ch {
            // 模拟接收处理
            time.Sleep(10 * time.Microsecond)
        }
    }()
    
    wg.Wait()
    return time.Since(start)
}

func bufferedChannelTest() time.Duration {
    start := time.Now()
    ch := make(chan int, 1000) // 缓冲通道
    
    var wg sync.WaitGroup
    wg.Add(2)
    
    // 发送者
    go func() {
        defer wg.Done()
        for i := 0; i < 10000; i++ {
            ch <- i // 可以填满缓冲区而不阻塞
        }
        close(ch)
    }()
    
    // 接收者
    go func() {
        defer wg.Done()
        for range ch {
            // 模拟接收处理
            time.Sleep(10 * time.Microsecond)
        }
    }()
    
    wg.Wait()
    return time.Since(start)
}

func main() {
    // 启动pprof
    go func() {
        fmt.Println("pprof服务启动在: http://localhost:6060/debug/pprof/")
        http.ListenAndServe("localhost:6060", nil)
    }()
    
    fmt.Println("开始无缓冲通道测试...")
    unbufferedTime := unbufferedChannelTest()
    fmt.Printf("无缓冲通道用时: %v\n", unbufferedTime)
    
    fmt.Println("开始缓冲通道测试...")
    bufferedTime := bufferedChannelTest()
    fmt.Printf("缓冲通道用时: %v\n", bufferedTime)
    
    fmt.Printf("性能提升: %.2f倍\n", float64(unbufferedTime)/float64(bufferedTime))
    
    fmt.Println("运行'go tool pprof http://localhost:6060/debug/pprof/profile'分析CPU使用情况")
    select {} // 保持程序运行以便进行pprof分析
}
```

---

## 3. 并发模式优化

### 3.1 优化工作池模式
```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

type Job struct {
    ID  int
    Num int
}

type Result struct {
    JobID int
    Sum   int
}

// 简单工作池实现
func simpleWorkerPool(numWorkers int, jobs []Job) []Result {
    results := make([]Result, 0, len(jobs))
    jobsChan := make(chan Job, len(jobs))
    resultsChan := make(chan Result, len(jobs))
    
    // 启动工作者
    var wg sync.WaitGroup
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            for job := range jobsChan {
                // 模拟计算
                sum := 0
                for i := 0; i < job.Num; i++ {
                    sum += i
                }
                resultsChan <- Result{JobID: job.ID, Sum: sum}
            }
        }(i)
    }
    
    // 发送任务
    for _, job := range jobs {
        jobsChan <- job
    }
    close(jobsChan)
    
    // 等待所有工作者完成
    go func() {
        wg.Wait()
        close(resultsChan)
    }()
    
    // 收集结果
    for result := range resultsChan {
        results = append(results, result)
    }
    
    return results
}

// 优化的工作池实现
func optimizedWorkerPool(numWorkers int, jobs []Job) []Result {
    results := make([]Result, len(jobs)) // 预分配结果空间
    
    // 将任务分成较大的块，减少通道操作
    batchSize := max(len(jobs)/numWorkers, 1)
    numBatches := (len(jobs) + batchSize - 1) / batchSize
    
    var wg sync.WaitGroup
    for b := 0; b < numBatches; b++ {
        wg.Add(1)
        
        // 计算每个批次的开始和结束索引
        start := b * batchSize
        end := min(start+batchSize, len(jobs))
        
        go func(startIdx, endIdx int) {
            defer wg.Done()
            
            for i := startIdx; i < endIdx; i++ {
                job := jobs[i]
                
                // 模拟计算
                sum := 0
                for j := 0; j < job.Num; j++ {
                    sum += j
                }
                
                // 直接写入结果
                results[i] = Result{JobID: job.ID, Sum: sum}
            }
        }(start, end)
    }
    
    wg.Wait()
    return results
}

// Helper函数
func min(a, b int) int {
    if a < b {
        return a
    }
    return b
}

func max(a, b int) int {
    if a > b {
        return a
    }
    return b
}

func main() {
    // 准备测试数据
    numJobs := 10000
    jobs := make([]Job, numJobs)
    for i := 0; i < numJobs; i++ {
        jobs[i] = Job{ID: i, Num: 1000000}
    }
    
    numWorkers := runtime.NumCPU()
    fmt.Printf("使用 %d 个工作者处理 %d 个任务\n", numWorkers, numJobs)
    
    // 测试简单工作池
    fmt.Println("测试简单工作池...")
    start := time.Now()
    results1 := simpleWorkerPool(numWorkers, jobs)
    simpleTime := time.Since(start)
    fmt.Printf("简单工作池完成，处理 %d 个结果，耗时: %v\n", len(results1), simpleTime)
    
    // 测试优化工作池
    fmt.Println("测试优化工作池...")
    start = time.Now()
    results2 := optimizedWorkerPool(numWorkers, jobs)
    optimizedTime := time.Since(start)
    fmt.Printf("优化工作池完成，处理 %d 个结果，耗时: %v\n", len(results2), optimizedTime)
    
    fmt.Printf("性能提升: %.2f倍\n", float64(simpleTime)/float64(optimizedTime))
}
```

### 3.2 减少Context切换开销
```go
package main

import (
    "fmt"
    "runtime"
    "sync"
    "time"
)

func highSwitchingWorkload() time.Duration {
    start := time.Now()
    var wg sync.WaitGroup
    
    // 创建很多小任务的goroutines
    for i := 0; i < 10000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            // 非常小的工作单元
            sum := 0
            for j := 0; j < 1000; j++ {
                sum += j
            }
        }()
    }
    
    wg.Wait()
    return time.Since(start)
}

func lowSwitchingWorkload() time.Duration {
    start := time.Now()
    var wg sync.WaitGroup
    
    // 创建与CPU核心数量相同的goroutines
    numWorkers := runtime.NumCPU()
    workPerWorker := 10000 / numWorkers
    
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            
            // 更大的工作单元
            for w := 0; w < workPerWorker; w++ {
                sum := 0
                for j := 0; j < 1000; j++ {
                    sum += j
                }
            }
        }()
    }
    
    wg.Wait()
    return time.Since(start)
}

func main() {
    fmt.Printf("CPU核心数: %d\n", runtime.NumCPU())
    runtime.GOMAXPROCS(runtime.NumCPU())
    
    fmt.Println("开始高切换开销测试...")
    highTime := highSwitchingWorkload()
    fmt.Printf("高切换开销用时: %v\n", highTime)
    
    fmt.Println("开始低切换开销测试...")
    lowTime := lowSwitchingWorkload()
    fmt.Printf("低切换开销用时: %v\n", lowTime)
    
    fmt.Printf("性能提升: %.2f倍\n", float64(highTime)/float64(lowTime))
}
```

---

## 4. 内存优化技术

### 4.1 减少内存分配
```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func withoutPreallocation() (time.Duration, uint64) {
    start := time.Now()
    
    var m1, m2 runtime.MemStats
    runtime.ReadMemStats(&m1)
    
    // 不预分配内存
    s := make([]int, 0)
    for i := 0; i < 1000000; i++ {
        s = append(s, i)
    }
    
    runtime.ReadMemStats(&m2)
    
    return time.Since(start), m2.TotalAlloc - m1.TotalAlloc
}

func withPreallocation() (time.Duration, uint64) {
    start := time.Now()
    
    var m1, m2 runtime.MemStats
    runtime.ReadMemStats(&m1)
    
    // 预分配内存
    s := make([]int, 0, 1000000)
    for i := 0; i < 1000000; i++ {
        s = append(s, i)
    }
    
    runtime.ReadMemStats(&m2)
    
    return time.Since(start), m2.TotalAlloc - m1.TotalAlloc
}

func main() {
    fmt.Println("测试不预分配内存的性能...")
    d1, m1 := withoutPreallocation()
    fmt.Printf("不预分配: 用时 %v, 分配内存 %d 字节\n", d1, m1)
    
    fmt.Println("测试预分配内存的性能...")
    d2, m2 := withPreallocation()
    fmt.Printf("预分配: 用时 %v, 分配内存 %d 字节\n", d2, m2)
    
    fmt.Printf("时间性能提升: %.2f倍\n", float64(d1)/float64(d2))
    fmt.Printf("内存分配减少: %.2f%%\n", 100*(1-float64(m2)/float64(m1)))
}
```

### 4.2 对象池复用
```go
package main

import (
    "bytes"
    "fmt"
    "sync"
    "time"
)

func withoutObjectPool() time.Duration {
    start := time.Now()
    var wg sync.WaitGroup
    
    for i := 0; i < 1000000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            
            // 每次创建新的buffer
            var buf bytes.Buffer
            buf.WriteString("Hello, World!")
            _ = buf.String()
        }()
        
        // 限制goroutine数量
        if i%1000 == 0 {
            wg.Wait()
        }
    }
    
    wg.Wait()
    return time.Since(start)
}

func withObjectPool() time.Duration {
    start := time.Now()
    
    // 创建对象池
    pool := &sync.Pool{
        New: func() interface{} {
            return new(bytes.Buffer)
        },
    }
    
    var wg sync.WaitGroup
    
    for i := 0; i < 1000000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            
            // 从池中获取对象
            buf := pool.Get().(*bytes.Buffer)
            buf.Reset() // 重置状态
            
            buf.WriteString("Hello, World!")
            _ = buf.String()
            
            // 放回池中
            pool.Put(buf)
        }()
        
        // 限制goroutine数量
        if i%1000 == 0 {
            wg.Wait()
        }
    }
    
    wg.Wait()
    return time.Since(start)
}

func main() {
    fmt.Println("测试不使用对象池的性能...")
    d1 := withoutObjectPool()
    fmt.Printf("不使用对象池: 用时 %v\n", d1)
    
    fmt.Println("测试使用对象池的性能...")
    d2 := withObjectPool()
    fmt.Printf("使用对象池: 用时 %v\n", d2)
    
    fmt.Printf("性能提升: %.2f倍\n", float64(d1)/float64(d2))
}
```

---

## 5. 提高并发吞吐量

### 5.1 批处理技术
```go
package main

import (
    "fmt"
    "sync"
    "time"
)

// 模拟数据处理函数
func processItem(item int) int {
    // 模拟处理耗时
    time.Sleep(time.Microsecond)
    return item * 2
}

// 单项处理
func processItemsOneByOne(items []int) []int {
    results := make([]int, len(items))
    for i, item := range items {
        results[i] = processItem(item)
    }
    return results
}

// 批处理
func processItemsInBatches(items []int, batchSize int) []int {
    results := make([]int, len(items))
    numBatches := (len(items) + batchSize - 1) / batchSize
    
    var wg sync.WaitGroup
    for b := 0; b < numBatches; b++ {
        wg.Add(1)
        
        go func(batchIndex int) {
            defer wg.Done()
            
            start := batchIndex * batchSize
            end := min(start+batchSize, len(items))
            
            for i := start; i < end; i++ {
                results[i] = processItem(items[i])
            }
        }(b)
    }
    
    wg.Wait()
    return results
}

func main() {
    // 准备数据
    const numItems = 1000
    items := make([]int, numItems)
    for i := range items {
        items[i] = i + 1
    }
    
    // 测试单项处理
    fmt.Println("开始单项处理测试...")
    start := time.Now()
    results1 := processItemsOneByOne(items)
    singleTime := time.Since(start)
    fmt.Printf("单项处理用时: %v, 结果数量: %d\n", singleTime, len(results1))
    
    // 测试批处理
    fmt.Println("开始批处理测试...")
    start = time.Now()
    results2 := processItemsInBatches(items, 100)
    batchTime := time.Since(start)
    fmt.Printf("批处理用时: %v, 结果数量: %d\n", batchTime, len(results2))
    
    fmt.Printf("性能提升: %.2f倍\n", float64(singleTime)/float64(batchTime))
}
```

### 5.2 并行流水线
```go
package main

import (
    "fmt"
    "sync"
    "time"
)

// 定义流水线阶段
func stage1(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            // 模拟处理
            time.Sleep(10 * time.Millisecond)
            out <- n * 2
        }
    }()
    return out
}

func stage2(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            // 模拟处理
            time.Sleep(20 * time.Millisecond)
            out <- n + 10
        }
    }()
    return out
}

func stage3(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            // 模拟处理
            time.Sleep(15 * time.Millisecond)
            out <- n * n
        }
    }()
    return out
}

// 简单顺序处理
func sequentialProcessing(nums []int) []int {
    results := make([]int, len(nums))
    
    for i, n := range nums {
        // 顺序应用所有阶段
        temp := n
        
        // 第一阶段
        time.Sleep(10 * time.Millisecond)
        temp = temp * 2
        
        // 第二阶段
        time.Sleep(20 * time.Millisecond)
        temp = temp + 10
        
        // 第三阶段
        time.Sleep(15 * time.Millisecond)
        temp = temp * temp
        
        results[i] = temp
    }
    
    return results
}

// 并行流水线处理
func pipelineProcessing(nums []int) []int {
    // 创建输入通道
    in := make(chan int)
    
    // 启动goroutine发送输入
    go func() {
        defer close(in)
        for _, n := range nums {
            in <- n
        }
    }()
    
    // 构建流水线
    stage1Out := stage1(in)
    stage2Out := stage2(stage1Out)
    stage3Out := stage3(stage2Out)
    
    // 收集结果
    var results []int
    for n := range stage3Out {
        results = append(results, n)
    }
    
    return results
}

// 扩展的并行流水线处理
func parallelPipelineProcessing(nums []int, parallelism int) []int {
    // 创建输入通道
    in := make(chan int)
    
    // 启动goroutine发送输入
    go func() {
        defer close(in)
        for _, n := range nums {
            in <- n
        }
    }()
    
    // 第一阶段多worker
    stage1OutChannels := make([]<-chan int, parallelism)
    for i := 0; i < parallelism; i++ {
        stage1OutChannels[i] = stage1(in)
    }
    
    // 合并第一阶段结果
    stage1Out := mergeChannels(stage1OutChannels)
    
    // 第二阶段多worker
    stage2OutChannels := make([]<-chan int, parallelism)
    for i := 0; i < parallelism; i++ {
        stage2OutChannels[i] = stage2(stage1Out)
    }
    
    // 合并第二阶段结果
    stage2Out := mergeChannels(stage2OutChannels)
    
    // 第三阶段多worker
    stage3OutChannels := make([]<-chan int, parallelism)
    for i := 0; i < parallelism; i++ {
        stage3OutChannels[i] = stage3(stage2Out)
    }
    
    // 合并第三阶段结果
    stage3Out := mergeChannels(stage3OutChannels)
    
    // 收集结果
    var results []int
    for n := range stage3Out {
        results = append(results, n)
    }
    
    return results
}

// 合并多个通道的辅助函数
func mergeChannels(cs []<-chan int) <-chan int {
    out := make(chan int)
    var wg sync.WaitGroup
    
    // 为每个输入通道启动一个goroutine
    wg.Add(len(cs))
    for _, c := range cs {
        go func(ch <-chan int) {
            defer wg.Done()
            for n := range ch {
                out <- n
            }
        }(c)
    }
    
    // 当所有输入通道关闭后，关闭输出通道
    go func() {
        wg.Wait()
        close(out)
    }()
    
    return out
}

func main() {
    // 准备数据
    nums := make([]int, 20)
    for i := range nums {
        nums[i] = i + 1
    }
    
    // 测试顺序处理
    fmt.Println("开始顺序处理测试...")
    start := time.Now()
    results1 := sequentialProcessing(nums)
    seqTime := time.Since(start)
    fmt.Printf("顺序处理用时: %v, 结果数量: %d\n", seqTime, len(results1))
    
    // 测试基本流水线
    fmt.Println("开始基本流水线测试...")
    start = time.Now()
    results2 := pipelineProcessing(nums)
    pipeTime := time.Since(start)
    fmt.Printf("基本流水线用时: %v, 结果数量: %d\n", pipeTime, len(results2))
    
    // 测试并行流水线
    fmt.Println("开始并行流水线测试...")
    start = time.Now()
    results3 := parallelPipelineProcessing(nums, 3)
    parPipeTime := time.Since(start)
    fmt.Printf("并行流水线用时: %v, 结果数量: %d\n", parPipeTime, len(results3))
    
    fmt.Printf("基本流水线vs顺序: 提升%.2f倍\n", float64(seqTime)/float64(pipeTime))
    fmt.Printf("并行流水线vs顺序: 提升%.2f倍\n", float64(seqTime)/float64(parPipeTime))
    fmt.Printf("并行流水线vs基本流水线: 提升%.2f倍\n", float64(pipeTime)/float64(parPipeTime))
}
```

---

## 6. 实战案例：高性能Web服务器

### 6.1 构建高性能HTTP服务器
```go
package main

import (
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
)

// 请求计数器
var (
    requestCount   int64
    successCount   int64
    errorCount     int64
    responseTimeNs int64
)

// 模拟数据库连接池
type DBPool struct {
    conns chan struct{}
}

func NewDBPool(maxConns int) *DBPool {
    pool := &DBPool{
        conns: make(chan struct{}, maxConns),
    }
    
    // 初始化连接池
    for i := 0; i < maxConns; i++ {
        pool.conns <- struct{}{}
    }
    
    return pool
}

func (p *DBPool) Acquire() {
    <-p.conns
}

func (p *DBPool) Release() {
    p.conns <- struct{}{}
}

// 模拟数据库操作
func queryDatabase() ([]map[string]interface{}, error) {
    // 模拟数据库操作耗时
    time.Sleep(50 * time.Millisecond)
    
    // 模拟返回数据
    results := make([]map[string]interface{}, 10)
    for i := 0; i < 10; i++ {
        results[i] = map[string]interface{}{
            "id":    i + 1,
            "name":  fmt.Sprintf("Item %d", i+1),
            "value": (i + 1) * 10,
        }
    }
    
    return results, nil
}

// 处理请求
func handleRequest(w http.ResponseWriter, r *http.Request, dbPool *DBPool) {
    start := time.Now()
    
    // 增加请求计数
    atomic.AddInt64(&requestCount, 1)
    
    // 从连接池获取连接
    dbPool.Acquire()
    defer dbPool.Release()
    
    // 查询数据
    results, err := queryDatabase()
    if err != nil {
        atomic.AddInt64(&errorCount, 1)
        http.Error(w, "Database error", http.StatusInternalServerError)
        return
    }
    
    // 构造响应
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(map[string]interface{}{
        "status":  "success",
        "results": results,
    })
    
    // 增加成功计数
    atomic.AddInt64(&successCount, 1)
    
    // 记录响应时间
    elapsed := time.Since(start).Nanoseconds()
    atomic.AddInt64(&responseTimeNs, elapsed)
}

// 统计数据
func statsHandler(w http.ResponseWriter, r *http.Request) {
    rc := atomic.LoadInt64(&requestCount)
    sc := atomic.LoadInt64(&successCount)
    ec := atomic.LoadInt64(&errorCount)
    rt := atomic.LoadInt64(&responseTimeNs)
    
    var avgResponseTime float64
    if rc > 0 {
        avgResponseTime = float64(rt) / float64(rc) / 1000000 // 转换为毫秒
    }
    
    stats := map[string]interface{}{
        "total_requests":      rc,
        "successful_requests": sc,
        "error_requests":      ec,
        "avg_response_time":   avgResponseTime,
        "goroutines":          runtime.NumGoroutine(),
    }
    
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(stats)
}

func main() {
    // 设置GOMAXPROCS
    numCPU := runtime.NumCPU()
    runtime.GOMAXPROCS(numCPU)
    fmt.Printf("服务器启动，使用 %d 个CPU核心\n", numCPU)
    
    // 创建数据库连接池
    dbPool := NewDBPool(100)
    
    // 设置HTTP处理函数
    http.HandleFunc("/api/data", func(w http.ResponseWriter, r *http.Request) {
        handleRequest(w, r, dbPool)
    })
    
    http.HandleFunc("/stats", statsHandler)
    
    // 启动服务器
    fmt.Println("服务器监听在 http://localhost:8080")
    fmt.Println("访问 http://localhost:8080/api/data 测试API")
    fmt.Println("访问 http://localhost:8080/stats 查看统计信息")
    
    if err := http.ListenAndServe(":8080", nil); err != nil {
        log.Fatal("Server error:", err)
    }
}
```

### 6.2 负载测试
使用以下命令进行负载测试：

```bash
# 使用hey工具进行测试
go install github.com/rakyll/hey@latest

# 发送1000个请求，50个并发
hey -n 1000 -c 50 http://localhost:8080/api/data
```

---

## 7. 学习检查点

- [ ] 理解如何使用pprof进行性能分析
- [ ] 能够识别并发程序中的锁竞争问题
- [ ] 掌握减少通道操作开销的技术
- [ ] 能够优化工作池实现提高性能
- [ ] 理解并应用内存优化技术
- [ ] 掌握批处理和流水线并行的实现方法
- [ ] 能够构建和优化高性能并发服务

---

并发性能调优是构建高性能Go应用程序的关键。通过系统地分析性能瓶颈，应用适当的优化技术，可以显著提高程序的吞吐量和响应速度。记住，优化应该建立在测量的基础上，而不是猜测。
