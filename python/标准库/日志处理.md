# Python日志处理

日志是应用程序运行时记录信息的方式，对于调试问题、监控应用状态和审计用户行为至关重要。Python 标准库中的 `logging` 模块提供了灵活而强大的日志记录功能，适用于小型脚本到大型企业级应用。本文详细介绍 Python 日志处理的基础知识、高级配置和最佳实践。

## 日志处理基础

### 为什么使用日志

相比于使用 `print()` 语句，使用专门的日志模块有以下优势：

1. **灵活性**：可以轻松配置日志的输出位置（控制台、文件、网络等）
2. **分级别记录**：可以设置不同的日志级别（调试、信息、警告、错误等）
3. **格式控制**：可以自定义日志消息的格式
4. **按需启用/禁用**：可以通过配置启用或禁用特定的日志输出，而不需要修改代码

### 日志级别

Python 的 `logging` 模块定义了以下几个日志级别（按严重程度递增）：

| 级别 | 数值 | 描述 |
|------|------|------|
| DEBUG | 10 | 详细信息，通常用于诊断问题 |
| INFO | 20 | 确认程序按预期运行 |
| WARNING | 30 | 表示可能出现问题的警告 |
| ERROR | 40 | 由于严重问题，程序的某些功能无法执行 |
| CRITICAL | 50 | 严重错误，表明程序可能无法继续运行 |

默认情况下，只有 WARNING 及以上级别的日志会被处理和显示。

### 基本使用

最简单的日志记录方式：

```python
import logging

# 记录不同级别的日志
logging.debug("这是一条调试信息")
logging.info("这是一条信息性消息")
logging.warning("这是一条警告消息")
logging.error("这是一条错误消息")
logging.critical("这是一条严重错误消息")
```

运行上述代码，只会看到 WARNING 及以上级别的消息：

```
WARNING:root:这是一条警告消息
ERROR:root:这是一条错误消息
CRITICAL:root:这是一条严重错误消息
```

### 配置日志级别

可以通过 `basicConfig()` 函数配置日志级别：

```python
import logging

# 配置日志级别为 DEBUG
logging.basicConfig(level=logging.DEBUG)

logging.debug("这是一条调试信息")
logging.info("这是一条信息性消息")
logging.warning("这是一条警告消息")
```

此时将看到所有级别的消息：

```
DEBUG:root:这是一条调试信息
INFO:root:这是一条信息性消息
WARNING:root:这是一条警告消息
```

### 配置日志格式

可以自定义日志消息的格式：

```python
import logging

# 配置日志格式
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logging.debug("这是一条调试信息")
logging.warning("这是一条警告消息")
```

输出示例：

```
2023-06-15 10:21:34,567 - root - DEBUG - 这是一条调试信息
2023-06-15 10:21:34,568 - root - WARNING - 这是一条警告消息
```

格式字符串中的占位符说明：

- `%(asctime)s`: 日志事件发生的时间
- `%(name)s`: 记录器的名称
- `%(levelname)s`: 日志级别的文本名称
- `%(message)s`: 日志消息内容
- `%(filename)s`: 发生日志事件的源文件名
- `%(module)s`: 发生日志事件的模块名
- `%(funcName)s`: 发生日志事件的函数名
- `%(lineno)d`: 发生日志事件的行号
- `%(process)d`: 进程ID
- `%(processName)s`: 进程名称
- `%(thread)d`: 线程ID
- `%(threadName)s`: 线程名称

### 将日志记录到文件

除了在控制台显示，还可以将日志记录到文件：

```python
import logging

# 配置日志输出到文件
logging.basicConfig(
    filename='app.log',  # 日志文件名
    filemode='w',        # 写入模式：'w' 覆盖，'a' 追加
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logging.debug("这是一条调试信息")
logging.info("这是一条信息性消息")
logging.warning("这是一条警告消息")
```

此时日志将写入当前目录下的 `app.log` 文件。

## 高级日志配置

### 创建和使用 Logger 对象

在大型应用中，通常会创建多个 logger，每个模块使用自己的 logger：

```python
import logging

# 创建 logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建控制台处理器并设置日志级别
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.DEBUG)

# 创建格式化器
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)

# 将处理器添加到 logger
logger.addHandler(console_handler)

# 使用 logger 记录日志
logger.debug('这是来自 my_app logger 的调试信息')
logger.info('这是来自 my_app logger 的信息')
logger.warning('这是来自 my_app logger 的警告')
```

### 同时记录到控制台和文件

可以设置多个处理器，将日志同时输出到不同的目标：

```python
import logging

# 创建 logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建控制台处理器
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)  # 控制台只显示 INFO 及以上级别

# 创建文件处理器
file_handler = logging.FileHandler('app.log')
file_handler.setLevel(logging.DEBUG)  # 文件记录所有级别的日志

# 创建格式化器
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)
file_handler.setFormatter(formatter)

# 将处理器添加到 logger
logger.addHandler(console_handler)
logger.addHandler(file_handler)

# 使用 logger 记录日志
logger.debug('这条消息只会记录到文件')
logger.info('这条消息会记录到文件和控制台')
logger.warning('这是一条警告消息')
```

### 按日期滚动日志文件

对于长期运行的应用，通常需要按日期滚动日志文件，避免单个日志文件过大：

```python
import logging
from logging.handlers import TimedRotatingFileHandler
import time

# 创建 logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建按时间滚动的文件处理器
# 每天凌晨滚动，保留 7 天的日志
handler = TimedRotatingFileHandler(
    'app.log',
    when='midnight',
    interval=1,
    backupCount=7
)
handler.setLevel(logging.DEBUG)

# 设置格式
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# 示例：持续记录日志
for i in range(3):
    logger.debug(f'调试消息 #{i+1}')
    logger.info(f'信息消息 #{i+1}')
    logger.warning(f'警告消息 #{i+1}')
    time.sleep(1)  # 模拟间隔
```

### 按大小滚动日志文件

也可以按文件大小滚动日志：

```python
import logging
from logging.handlers import RotatingFileHandler

# 创建 logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建按大小滚动的文件处理器
# 最大 5MB，最多保留 5 个备份文件
handler = RotatingFileHandler(
    'app.log',
    maxBytes=5*1024*1024,  # 5MB
    backupCount=5
)
handler.setLevel(logging.DEBUG)

# 设置格式
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# 记录一些日志
for i in range(10000):
    logger.debug(f'这是一条调试消息，索引：{i}')
```

当 `app.log` 达到 5MB 时，它将被重命名为 `app.log.1`，然后创建一个新的 `app.log` 文件继续记录。

### 通过配置文件设置日志

对于复杂的日志配置，可以使用配置文件：

```python
import logging
import logging.config

# 通过配置字典设置日志
config = {
    'version': 1,
    'formatters': {
        'standard': {
            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        },
        'simple': {
            'format': '%(levelname)s - %(message)s'
        },
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'simple',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'class': 'logging.FileHandler',
            'level': 'DEBUG',
            'formatter': 'standard',
            'filename': 'app.log',
            'mode': 'a',
        },
    },
    'loggers': {
        '': {  # root logger
            'handlers': ['console', 'file'],
            'level': 'DEBUG',
            'propagate': True
        },
        'my_app': {
            'handlers': ['file'],
            'level': 'DEBUG',
            'propagate': False
        },
        'my_app.sub_module': {
            'handlers': ['console'],
            'level': 'INFO',
            'propagate': True
        },
    }
}

# 应用配置
logging.config.dictConfig(config)

# 获取 logger 并记录日志
logger = logging.getLogger('my_app')
logger.debug('这是 my_app logger 的调试消息')
logger.info('这是 my_app logger 的信息消息')

sub_logger = logging.getLogger('my_app.sub_module')
sub_logger.debug('这条不会显示，因为控制台处理器级别是 INFO')
sub_logger.info('这是子模块的信息消息')
```

也可以使用 JSON 或 YAML 文件来存储配置，并使用 `logging.config.fileConfig()` 加载：

```python
import logging
import logging.config
import json

# 从文件加载配置
with open('logging_config.json', 'r') as f:
    config = json.load(f)

logging.config.dictConfig(config)

# 使用配置好的 logger
logger = logging.getLogger('my_app')
logger.info('从 JSON 配置文件加载的日志系统')
```

### 日志记录异常信息

记录异常时，可以包含完整的堆栈跟踪：

```python
import logging

logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建处理器和格式化器
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

try:
    # 尝试执行可能出错的代码
    result = 10 / 0
except Exception as e:
    # 记录异常，包含堆栈跟踪
    logger.error("发生错误", exc_info=True)
    
    # 或者使用 exception 方法，它等同于 error(..., exc_info=True)
    logger.exception("使用 exception 方法记录错误")
```

输出包含完整的堆栈跟踪信息：

```
2023-06-15 11:30:45,678 - my_app - ERROR - 发生错误
Traceback (most recent call last):
  File "example.py", line 15, in <module>
    result = 10 / 0
ZeroDivisionError: division by zero
2023-06-15 11:30:45,680 - my_app - ERROR - 使用 exception 方法记录错误
Traceback (most recent call last):
  File "example.py", line 15, in <module>
    result = 10 / 0
ZeroDivisionError: division by zero
```

### 自定义日志处理器

除了内置的处理器外，还可以创建自定义处理器，例如发送日志到 Syslog、数据库或通过电子邮件发送：

```python
import logging
import logging.handlers
import smtplib

# 创建 logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 创建邮件处理器，当出现严重错误时发送邮件
mail_handler = logging.handlers.SMTPHandler(
    mailhost=('smtp.example.com', 587),
    fromaddr='alerts@example.com',
    toaddrs=['admin@example.com'],
    subject='应用程序警报',
    credentials=('username', 'password'),
    secure=()  # 使用 TLS
)
mail_handler.setLevel(logging.CRITICAL)  # 只有严重错误才发送邮件

# 设置格式
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
mail_handler.setFormatter(formatter)
logger.addHandler(mail_handler)

# 记录一些日志
logger.debug('这是一条调试消息')
logger.critical('系统崩溃！这会触发邮件发送')
```

### 使用上下文信息记录日志

在复杂应用中，通常需要添加上下文信息，例如请求ID、用户ID等：

```python
import logging
import uuid
from contextvars import ContextVar

# 定义一个上下文变量来存储请求ID
request_id_var = ContextVar('request_id', default=None)

class RequestIdFilter(logging.Filter):
    """为日志记录添加请求ID"""
    
    def filter(self, record):
        record.request_id = request_id_var.get() or '-'
        return True

# 设置 logger 和过滤器
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - [%(request_id)s] - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)

request_filter = RequestIdFilter()
handler.addFilter(request_filter)
logger.addHandler(handler)

# 模拟处理请求
def process_request(path):
    # 为每个请求生成唯一ID
    request_id = str(uuid.uuid4())
    request_id_var.set(request_id)
    
    logger.info(f"开始处理请求: {path}")
    
    # 模拟一些处理逻辑
    logger.debug("验证用户...")
    logger.debug("获取数据...")
    
    if path == '/error':
        logger.error("处理请求时出错")
        return "错误"
    
    logger.info("请求处理成功")
    return "成功"

# 处理多个请求
process_request('/api/data')
process_request('/error')
process_request('/api/users')
```

每条日志消息现在包含请求ID：

```
2023-06-15 12:00:01,234 - [550e8400-e29b-41d4-a716-446655440000] - my_app - INFO - 开始处理请求: /api/data
2023-06-15 12:00:01,235 - [550e8400-e29b-41d4-a716-446655440000] - my_app - DEBUG - 验证用户...
...
```

## 日志处理的最佳实践

### 日志命名约定

使用模块路径作为 logger 名称，便于识别日志来源：

```python
# 在 my_app/api/users.py 文件中
import logging

# 使用 __name__ 获取当前模块的路径
logger = logging.getLogger(__name__)  # 'my_app.api.users'

logger.info("用户模块初始化")
```

### 适当的日志级别使用

根据信息的重要性选择合适的日志级别：

- **DEBUG**：详细的开发调试信息
- **INFO**：确认程序按预期运行的常规信息
- **WARNING**：指示可能的问题，程序仍能正常运行
- **ERROR**：由于严重问题，程序的某些功能无法正常工作
- **CRITICAL**：表明程序本身可能无法继续运行

```python
import logging

logger = logging.getLogger(__name__)

def process_order(order):
    # 调试信息，仅在开发环境关注
    logger.debug(f"接收到订单数据: {order}")
    
    if not order.get('id'):
        # 警告，可能导致问题但不是错误
        logger.warning("订单缺少ID字段")
    
    try:
        # 记录重要的业务事件
        logger.info(f"处理订单 #{order.get('id', 'unknown')}")
        
        if not order.get('items'):
            # 业务规则错误
            logger.error(f"订单 #{order.get('id', 'unknown')} 没有商品项")
            return False
        
        # 处理逻辑...
        
    except DatabaseError:
        # 系统级错误，影响功能
        logger.critical("数据库连接失败，无法处理订单", exc_info=True)
        return False
    
    return True
```

### 包含上下文信息

确保日志消息包含足够的上下文信息，便于问题排查：

```python
# 不好的日志记录
logger.error("数据库查询失败")

# 好的日志记录
logger.error(
    "数据库查询失败",
    extra={
        "query": "SELECT * FROM users WHERE id = %s",
        "params": (user_id,),
        "error_code": e.code
    }
)
```

### 使用结构化日志

对于复杂系统，考虑使用结构化日志（如 JSON 格式），便于机器处理和分析：

```python
import logging
import json
from datetime import datetime

class JsonFormatter(logging.Formatter):
    """将日志格式化为 JSON 字符串"""
    
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "name": record.name,
            "message": record.getMessage(),
        }
        
        # 添加异常信息
        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)
        
        # 添加额外字段
        if hasattr(record, "props"):
            log_data.update(record.props)
        
        return json.dumps(log_data)

# 使用结构化日志
logger = logging.getLogger("my_app")
logger.setLevel(logging.DEBUG)

handler = logging.StreamHandler()
handler.setFormatter(JsonFormatter())
logger.addHandler(handler)

# 记录带额外属性的日志
logger.info(
    "用户登录成功", 
    extra={"props": {"user_id": 12345, "ip": "192.168.1.1"}}
)
```

输出示例：

```json
{"timestamp": "2023-06-15T12:30:45.678901", "level": "INFO", "name": "my_app", "message": "用户登录成功", "user_id": 12345, "ip": "192.168.1.1"}
```

### 分离日志配置和应用代码

将日志配置从应用代码中分离，使用配置文件或环境变量控制日志行为：

```python
import logging
import logging.config
import os
import yaml

def setup_logging(
    default_path='logging.yaml',
    default_level=logging.INFO,
    env_key='LOG_CONFIG'
):
    """设置日志配置"""
    path = os.getenv(env_key, default_path)
    if os.path.exists(path):
        with open(path, 'rt') as f:
            config = yaml.safe_load(f.read())
        logging.config.dictConfig(config)
    else:
        logging.basicConfig(level=default_level)

# 应用启动时配置日志
setup_logging()

# 然后在应用的各个部分使用日志
logger = logging.getLogger(__name__)
logger.debug("应用启动")
```

### 在多进程环境中使用日志

在多进程环境中，需要确保日志文件不会被多个进程同时写入：

```python
import logging
import multiprocessing
from logging.handlers import RotatingFileHandler
import time

# 创建支持多进程的处理器
class MultiProcessSafeHandler(RotatingFileHandler):
    def __init__(self, filename, mode='a', maxBytes=0, backupCount=0, encoding=None):
        RotatingFileHandler.__init__(self, filename, mode, maxBytes, backupCount, encoding)
        # 使用进程锁
        self.lock = multiprocessing.Lock()
    
    def emit(self, record):
        # 获取锁然后写入日志
        with self.lock:
            super().emit(record)

def worker_process(name):
    # 在每个进程中配置日志
    logger = logging.getLogger(f'process.{name}')
    logger.setLevel(logging.INFO)
    
    # 确保处理器不会被重复添加
    if not logger.handlers:
        handler = MultiProcessSafeHandler('multi_process.log', maxBytes=1024*1024, backupCount=3)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    
    # 记录一些日志
    for i in range(5):
        logger.info(f"进程 {name} 正在工作: {i}")
        time.sleep(0.1)

if __name__ == '__main__':
    # 创建多个进程
    processes = []
    for i in range(3):
        p = multiprocessing.Process(target=worker_process, args=(f"Worker-{i}",))
        processes.append(p)
        p.start()
    
    # 等待所有进程完成
    for p in processes:
        p.join()
```

### 处理敏感信息

避免在日志中记录敏感信息，如密码、令牌等：

```python
import logging
import re

class SensitiveDataFilter(logging.Filter):
    """过滤敏感数据的日志过滤器"""
    
    def __init__(self, patterns=None):
        super().__init__()
        self.patterns = patterns or [
            (r'password\s*=\s*[\'"](.*?)[\'"]', r'password=*****'),
            (r'token\s*=\s*[\'"](.*?)[\'"]', r'token=*****'),
            (r'secret\s*=\s*[\'"](.*?)[\'"]', r'secret=*****'),
            (r'card_number\s*=\s*[\'"](.*?)[\'"]', r'card_number=*****')
        ]
    
    def filter(self, record):
        if isinstance(record.msg, str):
            for pattern, replacement in self.patterns:
                record.msg = re.sub(pattern, replacement, record.msg)
        return True

# 设置 logger 和过滤器
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

handler = logging.StreamHandler()
handler.addFilter(SensitiveDataFilter())
logger.addHandler(handler)

# 测试日志记录
logger.info("用户登录成功，token='abcd1234efgh5678'")
logger.debug("配置数据库，password='supersecret123'")
```

输出将被过滤：

```
INFO:my_app:用户登录成功，token=*****
DEBUG:my_app:配置数据库，password=*****
```

### 使用日志在生产环境中调试

在生产环境中，可以通过调整日志级别进行临时调试，而无需重启应用：

```python
import logging
import time
import threading

# 设置 logger
logger = logging.getLogger('my_app')
logger.setLevel(logging.INFO)  # 默认级别为 INFO

handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

def check_debug_flag():
    """定期检查是否需要开启调试日志"""
    while True:
        try:
            # 从配置文件、数据库或环境变量检查调试标志
            # 这里简化为从文件读取
            with open('debug_flag.txt', 'r') as f:
                debug_enabled = f.read().strip().lower() == 'true'
            
            # 更新日志级别
            if debug_enabled and logger.level != logging.DEBUG:
                logger.setLevel(logging.DEBUG)
                logger.info("已启用调试日志")
            elif not debug_enabled and logger.level == logging.DEBUG:
                logger.setLevel(logging.INFO)
                logger.info("已禁用调试日志")
        
        except Exception:
            pass  # 忽略读取错误
        
        time.sleep(60)  # 每分钟检查一次

# 启动后台线程检查调试标志
debug_checker = threading.Thread(target=check_debug_flag, daemon=True)
debug_checker.start()

# 应用主逻辑
def main():
    while True:
        logger.info("应用正在运行...")
        logger.debug("这是一些调试信息，仅在调试模式下可见")
        time.sleep(10)

if __name__ == '__main__':
    main()
```

在运行时，通过将 `debug_flag.txt` 文件内容更改为 "true"，可以动态启用调试日志。

## 与其他系统集成

### 集成到 Web 框架

在 Flask 应用中集成日志：

```python
import logging
from logging.handlers import RotatingFileHandler
import os
from flask import Flask, request, g

app = Flask(__name__)

# 确保日志目录存在
os.makedirs('logs', exist_ok=True)

# 设置应用日志
handler = RotatingFileHandler('logs/app.log', maxBytes=10485760, backupCount=10)
handler.setFormatter(logging.Formatter(
    '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
))
handler.setLevel(logging.INFO)
app.logger.addHandler(handler)
app.logger.setLevel(logging.INFO)
app.logger.info('应用启动')

# 请求中间件，添加请求ID
@app.before_request
def before_request():
    g.request_id = request.headers.get('X-Request-ID', '')
    app.logger.info(f'处理请求: {request.method} {request.path} (ID: {g.request_id})')

@app.route('/')
def index():
    app.logger.info('访问首页')
    return 'Hello, World!'

@app.route('/api/users/<user_id>')
def get_user(user_id):
    app.logger.info(f'获取用户信息: {user_id}')
    # 假设这里有数据库操作
    return {'id': user_id, 'name': 'John Doe'}

@app.errorhandler(Exception)
def handle_exception(e):
    app.logger.error(f'请求处理错误 (ID: {g.request_id})', exc_info=True)
    return {'error': str(e)}, 500

if __name__ == '__main__':
    app.run(debug=True)
```

### 集成到 ELK 堆栈

将日志发送到 Elasticsearch 进行集中管理和分析：

```python
import logging
import datetime
import socket
from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk

class ElasticsearchHandler(logging.Handler):
    """将日志发送到 Elasticsearch 的处理器"""
    
    def __init__(self, hosts, index_prefix='logs-'):
        super().__init__()
        self.hosts = hosts
        self.index_prefix = index_prefix
        self.es = Elasticsearch(hosts)
        self.hostname = socket.gethostname()
        self.actions = []
        self.max_batch = 500
    
    def emit(self, record):
        try:
            # 格式化日志消息
            log_entry = {
                '@timestamp': datetime.datetime.utcnow().isoformat(),
                'level': record.levelname,
                'logger': record.name,
                'message': self.format(record),
                'path': record.pathname,
                'lineno': record.lineno,
                'function': record.funcName,
                'hostname': self.hostname,
            }
            
            # 添加异常信息
            if record.exc_info:
                log_entry['exception'] = self.formatException(record.exc_info)
            
            # 添加额外字段
            if hasattr(record, 'props'):
                log_entry.update(record.props)
            
            # 添加到批处理队列
            index_name = f"{self.index_prefix}{datetime.datetime.utcnow().strftime('%Y.%m.%d')}"
            action = {
                '_index': index_name,
                '_source': log_entry
            }
            self.actions.append(action)
            
            # 批量提交
            if len(self.actions) >= self.max_batch:
                self.flush()
        
        except Exception:
            self.handleError(record)
    
    def flush(self):
        """将日志批量发送到 Elasticsearch"""
        if not self.actions:
            return
        
        try:
            bulk(self.es, self.actions)
            self.actions = []
        except Exception:
            # 错误处理
            self.actions = []
    
    def close(self):
        """关闭处理器时刷新剩余日志"""
        self.flush()
        super().close()

# 使用示例
logger = logging.getLogger('my_app')
logger.setLevel(logging.DEBUG)

# 添加 Elasticsearch 处理器
es_handler = ElasticsearchHandler(hosts=['http://elasticsearch:9200'])
es_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
es_handler.setFormatter(formatter)
logger.addHandler(es_handler)

# 同时也添加控制台处理器
console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# 记录一些日志
logger.info("应用启动", extra={"props": {"version": "1.0.0"}})
logger.warning("磁盘空间不足", extra={"props": {"free_space_mb": 512}})

try:
    # 模拟错误
    raise ValueError("示例错误")
except Exception:
    logger.error("操作失败", exc_info=True)

# 确保所有日志都被发送
es_handler.flush()
```

## 总结

Python 的 `logging` 模块提供了强大而灵活的日志记录功能，可以满足从简单脚本到复杂企业级应用的各种需求。掌握日志处理的基础知识和最佳实践，可以帮助你更有效地调试问题、监控应用状态并了解系统行为。

关键要点：

1. 合理选择日志级别，区分不同重要性的信息
2. 使用合适的处理器，将日志输出到相应的目标
3. 添加足够的上下文信息，便于问题排查
4. 遵循日志命名约定，便于识别日志来源
5. 对敏感信息进行过滤，确保安全性
6. 采用结构化日志格式，便于机器处理和分析
7. 将日志配置与应用代码分离，提高灵活性

通过实施这些最佳实践，你可以建立一个健壮的日志系统，为应用程序的开发、调试和运维提供有力支持。
